{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bdbf27f-89de-437e-bf6d-72af2a63782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon May 30 10:11:44 2022\n",
    "\n",
    "@author: roy.369\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "from scipy.interpolate import griddata\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.colorbar\n",
    "from matplotlib import rc\n",
    "mpl.rcParams['axes.linewidth'] = 3\n",
    "import matplotlib as mpl  \n",
    "mpl.rc('font',family='Times New Roman')\n",
    "from matplotlib.pyplot import cm\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "from scipy.optimize import curve_fit\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "from scipy.interpolate import CubicSpline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8a04726-15e0-4ee8-9a83-ae7e344a156d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arr_loc(val,X):\n",
    "   ind = 0\n",
    "   for i in range(len(X)):\n",
    "      if(round(X[i],2) == round(val,2)):\n",
    "         ind = i\n",
    "         break\n",
    "   return ind\n",
    "\n",
    "\n",
    "def power_fit(x,a1,m):\n",
    "    return a1*x**m\n",
    "  \n",
    "def linear_fit(x,a,b):\n",
    "    return a+b*x\n",
    "    \n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return array[idx],idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2df0b97-9923-42db-8bf8-a816cc09191b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_point_upper_half_grid(N):\n",
    "\n",
    "    r_lab = []\n",
    "    r_rel_x = []\n",
    "    r_rel_y = []\n",
    "    x_span = int((int(N))/2)+1\n",
    "    r_pair_1 = 0\n",
    "    for i in range(x_span):\n",
    "        for j in range(x_span):\n",
    "            if(i<=j):\n",
    "              r_lab.append(r_pair_1)  \n",
    "              r_rel_x.append(i)\n",
    "              r_rel_y.append(j)\n",
    "              r_pair_1 = r_pair_1+1\n",
    "\n",
    "    R_relative_1 = np.stack((r_rel_x,r_rel_y),axis = 1)\n",
    "    return R_relative_1,r_pair_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57b4c3d9-ed50-4953-943d-eff05db55ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_point_full_grid(N):\n",
    "\n",
    "    r_lab = []\n",
    "    r_rel_x = []\n",
    "    r_rel_y = []\n",
    "    x_span = int((int(N))/2)+1\n",
    "    r_pair_2 = 0\n",
    "    for i in range(x_span):\n",
    "        for j in range(x_span):\n",
    "              r_lab.append(r_pair_2)\n",
    "              r_rel_x.append(i)\n",
    "              r_rel_y.append(j)\n",
    "              r_pair_2 = r_pair_2+1\n",
    "\n",
    "    R_relative_2 = np.stack((r_rel_x,r_rel_y),axis = 1)\n",
    "    return R_relative_2,r_pair_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "780143b5-e6a1-49d0-bb48-ab945b782e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_point_grid_upper_half_bz(N):\n",
    "\n",
    "    K_lab = []\n",
    "    Kx = []\n",
    "    Ky = []\n",
    "    x_span = int((int(N))/2)+1\n",
    "    k_pair = 0\n",
    "    for i in range(x_span):\n",
    "        for j in range(x_span):\n",
    "            if(i<=j):\n",
    "              K_lab.append(k_pair)  \n",
    "              Kx.append(i)\n",
    "              Ky.append(j)\n",
    "              k_pair = k_pair+1\n",
    "    BZ = np.stack((K_lab,Kx,Ky),axis = 1)\n",
    "    \n",
    "    return BZ,k_pair\n",
    "\n",
    "\n",
    "def k_point_grid_full_bz(N):\n",
    "\n",
    "    K_lab = []\n",
    "    Kx = []\n",
    "    Ky = []\n",
    "    x_span = int((int(N))/2)+1\n",
    "    k_pair = 0\n",
    "    for i in range(x_span):\n",
    "        for j in range(x_span):\n",
    "              K_lab.append(k_pair)\n",
    "              Kx.append(i)\n",
    "              Ky.append(j)\n",
    "              k_pair = k_pair+1\n",
    "    BZ = np.stack((K_lab,Kx,Ky),axis = 1)\n",
    "    \n",
    "    return BZ,k_pair\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6f089b4-7f5f-4bb0-8558-f6b0b571225f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adj_mat_calc(N):\n",
    "\n",
    "    r_grid, r_rel_grid_size = r_point_full_grid(int(N))\n",
    "    r_rel_x = r_grid[:,0]\n",
    "    r_rel_y = r_grid[:,1]\n",
    "\n",
    "    r_2 = np.add(np.power(r_rel_x,2),np.power(r_rel_y,2))\n",
    "    r_2_unq = np.sort(np.unique(r_2))\n",
    "\n",
    "    rx_cord = []\n",
    "    ry_cord = []\n",
    "    r2 = []\n",
    "    rx = np.arange(int(int(N)/2),-1*int(int(N)/2),-1)\n",
    "    ry = np.arange(int(int(N)/2),-1*int(int(N)/2),-1)\n",
    "    for i in range(len(rx)):\n",
    "        for j in range(len(ry)):\n",
    "            rx_cord.append(rx[i])\n",
    "            ry_cord.append(ry[j])\n",
    "            r2.append(rx[i]*rx[i]+ry[j]*ry[j])\n",
    "\n",
    "    #plt.figure()\n",
    "    #plt.scatter(rx_cord,ry_cord,c=r2)\n",
    "\n",
    "    adj_mat = np.zeros(len(r_2_unq))\n",
    "    for i in range(len(r_2_unq)):\n",
    "        count = 0\n",
    "        for i2 in range(len(r2)):\n",
    "            if round(r2[i2],2) == round(r_2_unq[i],2):\n",
    "               count = count+1\n",
    "        adj_mat[i] = count\n",
    "    \n",
    "    return np.stack((r_2_unq,np.asarray(adj_mat)),axis = 1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7e5e7a51-f813-4b7c-b5fd-0a7ecd0a1030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_func_multiple_beta_hf(N,u_val,mu,dtau,trot,plot_title,plot_x_label,plot_y_label,x_val,y_val,y_val_err,plot_name):\n",
    "\n",
    "   color_1 = iter([\"red\",\"orange\",\"goldenrod\",\"blue\",\"purple\"])\n",
    "   plt.figure(figsize = (38,30))\n",
    "   #plt.title(plot_title,fontsize = 60)\n",
    "   plt.xticks([2,4,6,8,10],fontsize = 100)\n",
    "   plt.yticks([0.010,0.015,0.020,0.025,0.030],fontsize = 100)\n",
    "   #plt.xscale('log')\n",
    "   #plt.yscale('log') \n",
    "   #plt.ylabel(plot_y_label,fontsize = 60)\n",
    "   #plt.xlabel(plot_x_label,fontsize = 60)\n",
    "   #U_val = np.linspace(1.0,10.0,num=101)\n",
    "   #Hd_fit = 0.55*np.power(U_val,-2) \n",
    "   plt.tick_params(axis='both', which='major', direction='out', pad=20,length = 30, width = 2.5,labelsize = 120)\n",
    "   plt.tick_params(axis='both', which='minor', direction='out', pad=20,length = 15, width = 1.5,labelsize = 60)\n",
    "   for jj in range(len(trot)):\n",
    "       c_1 = next(color_1)\n",
    "       beta = (float(dtau))*(float(trot[jj]))\n",
    "       T = round(1/beta,2)\n",
    "       plt.errorbar(x_val,y_val[:,jj],yerr = y_val_err[:,jj],c=c_1,marker = 'o',markersize = 20, elinewidth = 3, capsize = 5,label = r\"T = %s\"%str(T))\n",
    "   #plt.plot(U_val,Hd_fit,linestyle = 'dashed',color=  'black',linewidth = 3)\n",
    "   #plt.ylim(top=0.1)  \n",
    "   #plt.grid(True,which='both')\n",
    "   #plt.axvspan(3.5, 4.5, facecolor='r', alpha=0.2)\n",
    "   #plt.axvspan(4.0, 6.0, facecolor='b', alpha=0.2)\n",
    "   plt.legend(loc='best',fontsize = 60,ncol = 5) \n",
    "   plt.tight_layout() \n",
    "   plt.savefig(plot_name)\n",
    "   plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4744aaca-df14-40de-ab11-86513beda1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_func_multiple_U_hf(N,u_val,mu,dtau,trot,plot_title,plot_x_label,plot_y_label,x_val,y_val,y_val_err,plot_name):\n",
    "\n",
    "   color_1 = iter(['blue','darkgreen','olive','darkgoldenrod','orange','red'])\n",
    "   plt.figure(figsize = (25,20))\n",
    "   #plt.title(plot_title,fontsize = 60)\n",
    "   plt.yticks([0.01,0.02,0.03],fontsize = 80)\n",
    "   plt.xticks(fontsize = 80)\n",
    "   #plt.xscale('log')\n",
    "   #plt.yscale('log') \n",
    "   #plt.ylabel(plot_y_label,fontsize = 60)\n",
    "   #plt.xlabel(plot_x_label,fontsize = 60)\n",
    "   #U_val = np.linspace(1.0,10.0,num=101)\n",
    "   U_val =[\"1.0\",\"4.0\",\"5.0\",\"6.0\",\"8.0\",\"10.0\"] \n",
    "   #Hd_fit = 0.55*np.power(U_val,-2) \n",
    "   for i in range(len(u_val)):\n",
    "       c_1 = next(color_1)\n",
    "       plt.errorbar(x_val,y_val[i,:],yerr = y_val_err[i,:],c=c_1,marker = 'o',markersize = 20, elinewidth = 3, capsize = 5,label = r\"U = %s\"%str(U_val[i]))\n",
    "   #plt.plot(U_val,Hd_fit,linestyle = 'dashed',color=  'black',linewidth = 3)\n",
    "   #plt.ylim(top=0.1)  \n",
    "   plt.grid(True,which='both')\n",
    "   #plt.axvspan(3.5, 4.5, facecolor='r', alpha=0.2)\n",
    "   #plt.axvspan(4.0, 6.0, facecolor='b', alpha=0.2)\n",
    "   plt.legend(loc='best',ncol=2,fontsize = 60) \n",
    "   plt.tight_layout() \n",
    "   plt.savefig(plot_name)\n",
    "   plt.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2123e23d-f761-441c-b983-d4496c13fb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equal_time_moment_moment_correlation_function_half_filling(Text_dir_main_corr_hf,Text_dir_main_eqm,Graph_dir_hf,N,u,mu,dtau,L):\n",
    "\n",
    "   r_grid, r_rel_grid_size = r_point_upper_half_grid(N)\n",
    "   r_rel_x = r_grid[:,0]\n",
    "   r_rel_y = r_grid[:,1]\n",
    "\n",
    "   r_2 = np.add(np.power(r_rel_x,2),np.power(r_rel_y,2))\n",
    "   r_2_unq = np.sort(np.unique(r_2))\n",
    "\n",
    "   M2_M2_corr_hf = np.zeros((len(u),len(L),len(r_2_unq)))\n",
    "   M2_M2_corr_hf_std = np.zeros((len(u),len(L),len(r_2_unq)))\n",
    "   \n",
    "   M2_M2_conn_corr_hf = np.zeros((len(u),len(L),len(r_2_unq)))\n",
    "   M2_M2_conn_corr_hf_std = np.zeros((len(u),len(L),len(r_2_unq)))\n",
    "   \n",
    "   Nrm_M2_M2_conn_corr_hf = np.zeros((len(u),len(L),len(r_2_unq)))\n",
    "   Nrm_M2_M2_conn_corr_hf_std = np.zeros((len(u),len(L),len(r_2_unq)))\n",
    "\n",
    "   Nden = np.zeros((len(u),len(L)))\n",
    "   Nden_std = np.zeros((len(u),len(L)))\n",
    "   Ndbn = np.zeros((len(u),len(L)))\n",
    "   Ndbn_std = np.zeros((len(u),len(L)))\n",
    "    \n",
    "   Nhln = np.zeros((len(u),len(L)))\n",
    "   Nhln_std = np.zeros((len(u),len(L)))\n",
    "    \n",
    "   M2 = np.zeros((len(u),len(L)))\n",
    "   M2_std = np.zeros((len(u),len(L)))\n",
    "\n",
    "    \n",
    "   U_val = np.zeros(len(u))\n",
    "   for i in range(len(u)):\n",
    "       U_val[i] = float(u[i])\n",
    "       \n",
    "   T_val = np.zeros(len(L))    \n",
    "   for k in range(len(L)):\n",
    "       T_val[k] = 1/(float(dtau)*float(L[k]))\n",
    "       \n",
    "   for i in range(len(u)):\n",
    "       for k in range(len(L)):\n",
    "                       \n",
    "           Text_dir_eqm = \"%s/Text_files_N_%s_U_%s_dtau_%s/Mu_%s/dtau_%s_L_%s/Thermodynamic_measurements\"%(Text_dir_main_eqm,N,u[i],dtau,mu,dtau,L[k])\n",
    "\n",
    "           filename_eqm_avg = '%s/Thermodynamic_measurements_normal_averaged_dictionary_N_%s_U_%s_mu_%s_dtau_%s_L_%s.pkl' %(Text_dir_eqm,N,u[i],mu,dtau,L[k])\n",
    "           with open(filename_eqm_avg, 'rb') as infile:\n",
    "                sys_measure_avg = pickle.load(infile)\n",
    "\n",
    "           filename_eqm_std = '%s/Thermodynamic_measurements_normal_standard_deviation_dictionary_N_%s_U_%s_mu_%s_dtau_%s_L_%s.pkl' %(Text_dir_eqm,N,u[i],mu,dtau,L[k])\n",
    "           with open(filename_eqm_std, 'rb') as infile:\n",
    "                sys_measure_std = pickle.load(infile)\n",
    "\n",
    "           Nden[i][k] = sys_measure_avg['Density averaged']\n",
    "           Nden_std[i][k] = sys_measure_std['Density standard deviation']\n",
    "           Ndbn[i,k] = sys_measure_avg['Doublon number averaged']\n",
    "           Ndbn_std[i,k] = sys_measure_std['Doublon number standard deviation']\n",
    "           \n",
    "           M2[i][k] = Nden[i][k]-2*Ndbn[i][k]\n",
    "           M2_std[i][k] = np.sqrt(4*Ndbn_std[i][k]*Ndbn_std[i][k]+Nden_std[i][k]*Nden_std[i][k])\n",
    "           \n",
    "           Text_dir_m2_m2_corr_hf = '%s/Text_files_N_%s_U_%s_dtau_%s/Mu_%s/dtau_%s_L_%s/Moment_moment_correlation_functions'%(Text_dir_main_corr_hf,N,u[i],dtau,mu,dtau,L[k])\n",
    "           Text_dir_m2_m2_conn_corr_hf = '%s/Text_files_N_%s_U_%s_dtau_%s/Mu_%s/dtau_%s_L_%s/Moment_moment_connected_correlation_functions'%(Text_dir_main_corr_hf,N,u[i],dtau,mu,dtau,L[k])\n",
    "\n",
    "           filename_m2_m2_corr = '%s/Equal_time_Moment_Moment_correlation_real_space_neighbor_averaged_normal_avg_N_%s_U_%s_mu_%s_dtau_%s_L_%s.dat'%(Text_dir_m2_m2_corr_hf,N,u[i],mu,dtau,L[k])\n",
    "           M2_M2_corr_hf[i,k,:],M2_M2_corr_hf_std[i,k,:] = np.loadtxt(filename_m2_m2_corr,unpack = 'True', usecols = [1,2])\n",
    "\n",
    "           filename_m2_m2_conn_corr = '%s/Equal_time_Moment_Moment_connected_correlation_real_space_neighbor_averaged_normal_avg_N_%s_U_%s_mu_%s_dtau_%s_L_%s.dat'%(Text_dir_m2_m2_conn_corr_hf,N,u[i],mu,dtau,L[k])\n",
    "           M2_M2_conn_corr_hf[i,k,:],M2_M2_conn_corr_hf_std[i,k,:] = np.loadtxt(filename_m2_m2_conn_corr,unpack = 'True', usecols = [1,2])\n",
    "\n",
    "\n",
    "           for r in range(len(r_2_unq)):\n",
    "               \n",
    "               Nrm_M2_M2_conn_corr_hf[i,k,r] = (1/(M2[i][k]*M2[i][k]))*(M2_M2_conn_corr_hf[i,k,r])\n",
    "               Nrm_M2_M2_conn_corr_hf_std[i,k,r] = Nrm_M2_M2_conn_corr_hf[i,k,r]*(M2_M2_conn_corr_hf_std[i,k,r]/M2_M2_conn_corr_hf[i,k,r]+2*M2_std[i][k]/M2[i][k])\n",
    "               \n",
    " \n",
    "   M2_M2_corr_hf_n0 = np.zeros((len(u),len(L)))\n",
    "   M2_M2_corr_hf_n1 = np.zeros((len(u),len(L)))\n",
    "   M2_M2_corr_hf_n2 = np.zeros((len(u),len(L)))\n",
    "   M2_M2_corr_hf_n3 = np.zeros((len(u),len(L)))\n",
    "\n",
    "   M2_M2_corr_hf_n0_std = np.zeros((len(u),len(L)))\n",
    "   M2_M2_corr_hf_n1_std = np.zeros((len(u),len(L)))\n",
    "   M2_M2_corr_hf_n2_std = np.zeros((len(u),len(L)))\n",
    "   M2_M2_corr_hf_n3_std = np.zeros((len(u),len(L)))\n",
    "\n",
    "   M2_M2_conn_corr_hf_n0 = np.zeros((len(u),len(L)))\n",
    "   M2_M2_conn_corr_hf_n0_anl = np.zeros((len(u),len(L)))\n",
    "   M2_M2_conn_corr_hf_n1 = np.zeros((len(u),len(L)))\n",
    "   M2_M2_conn_corr_hf_n2 = np.zeros((len(u),len(L)))\n",
    "   M2_M2_conn_corr_hf_n3 = np.zeros((len(u),len(L)))\n",
    "    \n",
    "   M2_M2_conn_corr_hf_n0_std = np.zeros((len(u),len(L)))\n",
    "\n",
    "   M2_M2_conn_corr_hf_n0_anl_std = np.zeros((len(u),len(L)))\n",
    "   M2_M2_conn_corr_hf_n1_std = np.zeros((len(u),len(L)))\n",
    "   M2_M2_conn_corr_hf_n2_std = np.zeros((len(u),len(L)))\n",
    "   M2_M2_conn_corr_hf_n3_std = np.zeros((len(u),len(L)))\n",
    "\n",
    "   Nrm_M2_M2_conn_corr_hf_n0 = np.zeros((len(u),len(L)))\n",
    "   Nrm_M2_M2_conn_corr_hf_n1 = np.zeros((len(u),len(L)))\n",
    "   Nrm_M2_M2_conn_corr_hf_n2 = np.zeros((len(u),len(L)))\n",
    "   Nrm_M2_M2_conn_corr_hf_n3 = np.zeros((len(u),len(L)))\n",
    "    \n",
    "   Nrm_M2_M2_conn_corr_hf_n0_std = np.zeros((len(u),len(L)))\n",
    "   Nrm_M2_M2_conn_corr_hf_n1_std = np.zeros((len(u),len(L)))\n",
    "   Nrm_M2_M2_conn_corr_hf_n2_std = np.zeros((len(u),len(L)))\n",
    "   Nrm_M2_M2_conn_corr_hf_n3_std = np.zeros((len(u),len(L)))\n",
    "\n",
    "\n",
    "   for i in range(len(u)):\n",
    "       for k in range(len(L)):\n",
    "\n",
    "           M2_M2_corr_hf_n0[i][k] = M2_M2_corr_hf[i][k][0]\n",
    "           M2_M2_corr_hf_n1[i][k] = M2_M2_corr_hf[i][k][1]\n",
    "           M2_M2_corr_hf_n2[i][k] = M2_M2_corr_hf[i][k][2]\n",
    "           M2_M2_corr_hf_n3[i][k] = M2_M2_corr_hf[i][k][3]\n",
    "\n",
    "           M2_M2_corr_hf_n0_std[i][k] = M2_M2_corr_hf_std[i][k][0]\n",
    "           M2_M2_corr_hf_n1_std[i][k] = M2_M2_corr_hf_std[i][k][1]\n",
    "           M2_M2_corr_hf_n2_std[i][k] = M2_M2_corr_hf_std[i][k][2]\n",
    "           M2_M2_corr_hf_n3_std[i][k] = M2_M2_corr_hf_std[i][k][3]\n",
    "\n",
    "           M2_M2_conn_corr_hf_n0[i][k] = M2_M2_conn_corr_hf[i][k][0]\n",
    "\n",
    "           M2_M2_conn_corr_hf_n0_anl[i][k] = M2[i][k]*(1-M2[i][k])\n",
    "           M2_M2_conn_corr_hf_n1[i][k] = M2_M2_conn_corr_hf[i][k][1]\n",
    "           M2_M2_conn_corr_hf_n2[i][k] = M2_M2_conn_corr_hf[i][k][2]\n",
    "           M2_M2_conn_corr_hf_n3[i][k] = M2_M2_conn_corr_hf[i][k][3]\n",
    "           \n",
    "           M2_M2_conn_corr_hf_n0_std[i][k] = M2_M2_conn_corr_hf_std[i][k][0]\n",
    "           M2_M2_conn_corr_hf_n0_anl_std[i][k] = np.sqrt(M2_std[i][k]*M2_std[i][k]+4*M2_std[i][k]*M2_std[i][k]*M2[i][k]*M2[i][k])\n",
    "           M2_M2_conn_corr_hf_n1_std[i][k] = M2_M2_conn_corr_hf_std[i][k][1]\n",
    "           M2_M2_conn_corr_hf_n2_std[i][k] = M2_M2_conn_corr_hf_std[i][k][2]\n",
    "           M2_M2_conn_corr_hf_n3_std[i][k] = M2_M2_conn_corr_hf_std[i][k][3]\n",
    "\n",
    "           Nrm_M2_M2_conn_corr_hf_n0[i][k] = Nrm_M2_M2_conn_corr_hf[i][k][0]\n",
    "           Nrm_M2_M2_conn_corr_hf_n1[i][k] = Nrm_M2_M2_conn_corr_hf[i][k][1]\n",
    "           Nrm_M2_M2_conn_corr_hf_n2[i][k] = Nrm_M2_M2_conn_corr_hf[i][k][2]\n",
    "           Nrm_M2_M2_conn_corr_hf_n3[i][k] = Nrm_M2_M2_conn_corr_hf[i][k][3]\n",
    "           \n",
    "           Nrm_M2_M2_conn_corr_hf_n0_std[i][k] = Nrm_M2_M2_conn_corr_hf_std[i][k][0]\n",
    "           Nrm_M2_M2_conn_corr_hf_n1_std[i][k] = Nrm_M2_M2_conn_corr_hf_std[i][k][1]\n",
    "           Nrm_M2_M2_conn_corr_hf_n2_std[i][k] = Nrm_M2_M2_conn_corr_hf_std[i][k][2]\n",
    "           Nrm_M2_M2_conn_corr_hf_n3_std[i][k] = Nrm_M2_M2_conn_corr_hf_std[i][k][3]\n",
    "           \n",
    "           \n",
    "   Pl_title_n0 = r\"$\\langle h_i d_j \\rangle_{C}$ |i-j|=0.0, $N=%sx%s, n = 1$\"%(N,N)\n",
    "   Pl_title_n1 = r\"$\\langle h_i d_j \\rangle_{C}$ |i-j|=1.0, $N=%sx%s, n = 1$\"%(N,N)\n",
    "   Pl_title_n2 = r\"$\\langle h_i d_j \\rangle_{C}$ |i-j|=1.414, $N=%sx%s, n = 1$\"%(N,N)\n",
    "   Pl_title_n3 = r\"$\\langle h_i d_j \\rangle_{C}$ |i-j|=2.0, $N=%sx%s, n = 1$\"%(N,N)\n",
    "\n",
    "   Pl_y_lab = r\"$\\langle h_i d_j \\rangle_{C}$\"\n",
    "   Pl_x_lab = r\"$U$\"\n",
    "\n",
    "\n",
    "   #=========================================================Comparing_different_T=============================== \n",
    "   Pl_name_n1 = \"%s/T_comp_Moment_moment_correlation_1st_nearest_neighbor_averaged_normal_averaged_half_filling_N_%s_dtau_%s.png\"%(Graph_dir_hf,N,dtau)\n",
    "   Pl_name_conn_n1 = \"%s/T_comp_Moment_moment_correlation_connected_1st_nearest_neighbor_averaged_normal_averaged_half_filling_N_%s_dtau_%s.png\"%(Graph_dir_hf,N,dtau)\n",
    "   Pl_name_nrm_conn_n1 = \"%s/T_comp_Normalized_Moment_moment_correlation_connected_1st_nearest_neighbor_averaged_normal_averaged_half_filling_N_%s_dtau_%s.png\"%(Graph_dir_hf,N,dtau)\n",
    "   Pl_name_conn_n0 = \"%s/T_comp_Moment_moment_correlation_connected_onsite_normal_averaged_half_filling_N_%s_dtau_%s.png\"%(Graph_dir_hf,N,dtau)\n",
    "   Pl_name_conn_n0_anl = \"%s/T_comp_analytical_Moment_moment_correlation_connected_onsite_half_filling_N_%s_dtau_%s.png\"%(Graph_dir_hf,N,dtau)\n",
    "        \n",
    "   Pl_name_m2 = \"%s/T_comp_Local_moment_normal_averaged_half_filling_N_%s_dtau_%s.png\"%(Graph_dir_hf,N,dtau)\n",
    "  \n",
    "   plot_func_multiple_beta_hf(N,u,mu,dtau,L,Pl_title_n1,Pl_x_lab,Pl_y_lab,U_val,M2_M2_corr_hf_n1,M2_M2_corr_hf_n1_std,Pl_name_n1)\n",
    "   plot_func_multiple_beta_hf(N,u,mu,dtau,L,Pl_title_n2,Pl_x_lab,Pl_y_lab,U_val,M2_M2_conn_corr_hf_n1,M2_M2_conn_corr_hf_n1_std,Pl_name_conn_n1)\n",
    "   plot_func_multiple_beta_hf(N,u,mu,dtau,L,Pl_title_n3,Pl_x_lab,Pl_y_lab,U_val,Nrm_M2_M2_conn_corr_hf_n1,Nrm_M2_M2_conn_corr_hf_n1_std,Pl_name_nrm_conn_n1)\n",
    "   plot_func_multiple_beta_hf(N,u,mu,dtau,L,Pl_title_n3,Pl_x_lab,Pl_y_lab,U_val,M2,M2_std,Pl_name_m2)\n",
    "   plot_func_multiple_beta_hf(N,u,mu,dtau,L,Pl_title_n2,Pl_x_lab,Pl_y_lab,U_val,M2_M2_conn_corr_hf_n0,M2_M2_conn_corr_hf_n0_std,Pl_name_conn_n0)\n",
    "   plot_func_multiple_beta_hf(N,u,mu,dtau,L,Pl_title_n2,Pl_x_lab,Pl_y_lab,U_val,M2_M2_conn_corr_hf_n0_anl,M2_M2_conn_corr_hf_n0_anl_std,Pl_name_conn_n0_anl)\n",
    "    \n",
    "   #Pl_name_n1_u = \"%s/U_comp_Moment_moment_correlation_1st_nearest_neighbor_averaged_normal_averaged_half_filling_N_%s_dtau_%s.png\"%(Graph_dir_hf,N,dtau)\n",
    "   #Pl_name_conn_n1_u = \"%s/U_comp_Moment_moment_correlation_connected_1st_nearest_neighbor_averaged_normal_averaged_half_filling_N_%s_dtau_%s.png\"%(Graph_dir_hf,N,dtau)\n",
    "   #Pl_name_nrm_conn_n1_u = \"%s/U_comp_Normalized_Moment_moment_correlation_connected_1st_nearest_neighbor_averaged_normal_averaged_half_filling_N_%s_dtau_%s.png\"%(Graph_dir_hf,N,dtau)\n",
    "   \n",
    "   #Pl_name_m2_u = \"%s/U_comp_Local_moment_normal_averaged_half_filling_N_%s_dtau_%s.png\"%(Graph_dir_hf,N,dtau)\n",
    "  \n",
    "   #plot_func_multiple_U_hf(N,u,mu,dtau,L,Pl_title_n1,Pl_x_lab,Pl_y_lab,T_val,M2_M2_corr_hf_n1,M2_M2_corr_hf_n1_std,Pl_name_n1_u)\n",
    "   #plot_func_multiple_U_hf(N,u,mu,dtau,L,Pl_title_n2,Pl_x_lab,Pl_y_lab,T_val,M2_M2_conn_corr_hf_n1,M2_M2_conn_corr_hf_n1_std,Pl_name_conn_n1_u)\n",
    "   #plot_func_multiple_U_hf(N,u,mu,dtau,L,Pl_title_n3,Pl_x_lab,Pl_y_lab,T_val,Nrm_M2_M2_conn_corr_hf_n1,Nrm_M2_M2_conn_corr_hf_n1_std,Pl_name_nrm_conn_n1_u)\n",
    "   #plot_func_multiple_U_hf(N,u,mu,dtau,L,Pl_title_n3,Pl_x_lab,Pl_y_lab,T_val,M2,M2_std,Pl_name_m2_u)\n",
    "    \n",
    "   #=================================Fitting data==========================================\n",
    "\n",
    "   #n_pts = 801\n",
    "   #U_fit = np.linspace(1.00,10.00,num=n_pts)\n",
    "   #Cmm1_fit = np.zeros((len(U_fit),len(L)))\n",
    "   #Nrm_Cmm1_fit = np.zeros((len(U_fit),len(L)))\n",
    "   \n",
    "   #U_max_fit = np.zeros(len(L))\n",
    "   #Nrm_U_max_fit = np.zeros(len(L))\n",
    "   #U_max_qmc = np.zeros(len(L))\n",
    "\n",
    "   #Graph_dir_fit = \"%s/Data_fit_polynomial\"%Graph_dir_hf\n",
    "   #if not os.path.exists(Graph_dir_fit):\n",
    "   #   os.makedirs(Graph_dir_fit)\n",
    "\n",
    "\n",
    "   #for k in range(len(L)):\n",
    "   #    T_val[k] = 1/(float(dtau)*float(L[k]))\n",
    "   #    Poly_fit = np.polynomial.polynomial.Polynomial(np.polynomial.polynomial.polyfit(U_val,M2_M2_conn_corr_hf_n1[:,k],10))\n",
    "   #    Cmm1_fit[:,k] = Poly_fit(U_fit)\n",
    "   #    Nrm_Poly_fit = np.polynomial.polynomial.Polynomial(np.polynomial.polynomial.polyfit(U_val,Nrm_M2_M2_conn_corr_hf_n1[:,k],10))\n",
    "   #    Nrm_Cmm1_fit[:,k] = Nrm_Poly_fit(U_fit)    \n",
    "       \n",
    "   #    plt.figure(figsize = (20,20))\n",
    "   #    plt.xticks(fontsize = 40)\n",
    "   #    plt.yticks(fontsize = 40)\n",
    "   #    plt.xlabel(\"U\",fontsize = 40)\n",
    "   #    plt.ylabel(r\"$C_{mm}(1)$\",fontsize = 40)\n",
    "   #    plt.errorbar(U_val,Nrm_M2_M2_conn_corr_hf_n1[:,k],yerr = Nrm_M2_M2_conn_corr_hf_n1_std[:,k],marker = 'o',markersize = 15,capsize =5, elinewidth = 3)\n",
    "   #    plt.plot(U_fit,Nrm_Cmm1_fit[:,k],linewidth = 3,label = \"Data_fit\")\n",
    "   #    plt.legend(loc = 'best',fontsize =40)\n",
    "   #    plt.savefig(\"%s/Data_fit_normalized_correlator_N_%s_dtau_%s_L_%s_normal_avg.png\"%(Graph_dir_fit,N,dtau,L[k]))\n",
    "\n",
    "   #    plt.figure(figsize = (20,20))\n",
    "   #    plt.xticks(fontsize = 40)\n",
    "   #    plt.yticks(fontsize = 40)\n",
    "   #    plt.xlabel(\"U\",fontsize = 40)\n",
    "   #    plt.ylabel(r\"$C_{mm}(1)$\",fontsize = 40)\n",
    "   #    plt.errorbar(U_val,M2_M2_conn_corr_hf_n1[:,k],yerr = M2_M2_conn_corr_hf_n1_std[:,k],marker = 'o',markersize = 15,capsize =5, elinewidth = 3)\n",
    "   #    plt.plot(U_fit,Cmm1_fit[:,k],linewidth = 3,label = \"Data_fit\")\n",
    "   #    plt.legend(loc = 'best',fontsize =40)\n",
    "   #    plt.savefig(\"%s/Data_fit_correlator_N_%s_dtau_%s_L_%s_normal_avg.png\"%(Graph_dir_fit,N,dtau,L[k]))\n",
    "\n",
    "       \n",
    "   #    U_max_fit[k] = U_fit[np.argmax(Cmm1_fit[:,k])]\n",
    "   #    Nrm_U_max_fit[k] = U_fit[np.argmax(Nrm_Cmm1_fit[:,k])]\n",
    "   #    U_max_qmc[k] = U_val[np.argmax(Nrm_M2_M2_conn_corr_hf_n1[:,k])]\n",
    "\n",
    "\n",
    "   #U_val_LDOS = np.asarray([3.20,3.30,3.40,3.50,3.60,3.70,3.80,3.90,4.00,4.10,4.20,4.300,4.40,4.50,4.700,4.800,4.900,5.00]) #,5.100,5.200,5.500,6.000,6.500])\n",
    "   #T_c_LDOS =   np.asarray([0.30,0.30,0.30,0.30,0.30,0.30,0.30,0.33,0.33,0.33,0.33,0.345,0.40,0.40,0.417,0.417,0.455,0.50]) #,0.556,0.556,0.667,0.833,1.000])\n",
    "\n",
    "   #print(T_val,\"T\")\n",
    "   #print(U_max_fit,\"U_fit\")\n",
    "   #print(U_max_qmc,\"U_qmc\")\n",
    "\n",
    "   #plt.figure(figsize = (25,20))\n",
    "   #plt.xticks(fontsize = 80)\n",
    "   #plt.yticks(fontsize = 80)\n",
    "   #plt.plot(T_val,U_max_fit,marker = \"o\",markersize = 25,label = \"Conn\")\n",
    "   #plt.plot(T_val,Nrm_U_max_fit,marker = \"o\",markersize = 25,label = \"Nrm\")    \n",
    "   #plt.plot(T_c_LDOS,U_val_LDOS,marker = \"^\",markersize = 25) \n",
    "   #plt.grid(True,which='both')\n",
    "   #plt.legend(loc = 'best',fontsize = 50) \n",
    "   #plt.savefig(\"%s/T_max_normalized_moment_correlations.png\"%Graph_dir_hf) \n",
    "   #coef = np.polyfit(T_val,U_max_fit,1)\n",
    "   #line_fit = np.poly1d(coef)\n",
    "   #T_x = np.arange(0,1.1,0.1)\n",
    "   #U_x = line_fit(T_x)\n",
    "   #T_w = np.array([0.2848484848484848,0.19878787878787876,0.1533333333333333,0.12424242424242421,0.09999999999999998])\n",
    "   #U_w = np.array([6.7899159663865545,6.369747899159664,6.30252100840336,6.100840336134454,6])\n",
    "   #print(U_x[0])\n",
    "   #plt.figure(figsize = (30,20))\n",
    "   #plt.xlabel(\"T\",fontsize = 80)\n",
    "   #plt.ylabel(r\"$U_{max}$\",fontsize = 80)\n",
    "   #plt.xticks([0.0,0.25,0.5,0.75,1.0],fontsize = 120)\n",
    "   #plt.yticks([U_x[0],5.75,6.00,6.25,6.50,6.75,7.00],fontsize = 120)\n",
    "   #plt.plot(T_val,U_max_fit,marker = 'o',markersize = 55,label = \"Data_fit,n = %s\"%str(n_pts))\n",
    "   #plt.plot(T_val,U_max_qmc,marker = 'o',markersize = 15,linewidth = 5,label = \"QMC\")\n",
    "   #plt.plot(T_x,U_x,'--k',linewidth = 10)\n",
    "   #plt.plot(T_w,U_w,marker = 's',markersize = 55,label = \"Widom line\")\n",
    "   #plt.legend(loc = 'best',fontsize = 60)\n",
    "   #plt.axhline(y=U_x[0],linestyle = '--',color = 'b')\n",
    "   #plt.grid('True')\n",
    "   #plt.xlim(0,1.01)\n",
    "   #plt.text(4, 1, 'y=%s'%(U_x[0]))\n",
    "   #plt.tight_layout()\n",
    "   #plt.savefig(\"%s/U_max_Cmm1_N_%s_dtau_%s_n_points_%s.png\"%(Graph_dir_hf,N,dtau,str(n_pts)))\n",
    "\n",
    "\n",
    "   #color_1 = iter(cm.gnuplot(np.linspace(0, 1, len(L)+1)))\n",
    "   #plt.figure(figsize = (25,20))\n",
    "   #plt.xticks([2.0,4.0,6.0,8.0,10.0],fontsize = 80)\n",
    "   #plt.yticks(fontsize = 80)\n",
    "   #plt.xlabel(\"U\",fontsize = 40)\n",
    "   #plt.ylabel(r\"$C_{mm}(1)$\",fontsize = 40)\n",
    "   #for k in range(len(L)-1,-1,-1):\n",
    "   #    c_1 = next(color_1)\n",
    "   #    plt.errorbar(U_val[Uc1_ind:Uc2_ind+1],Mmt_Mmt_corr_hf_n1[Uc1_ind:Uc2_ind+1,k],yerr = Mmt_Mmt_corr_hf_n1_std[Uc1_ind:Uc2_ind+1,k], ls='none',c=c_1,marker = 'o',markersize = 25,capsize =5, elinewidth = 3)\n",
    "   #    plt.plot(U_fit,Cmm1_fit[:,k],c=c_1,linestyle = '--',linewidth = 3,label = \"T=%s\"%str(round(T_val[k],2)))\n",
    "   #plt.legend(loc = 'upper left',fontsize =50)\n",
    "   #plt.axvspan(3.5,4.2,color='red',alpha=0.5)\n",
    "  # plt.axvspan(4.5,6.65,color='blue',alpha=0.3)\n",
    "  # plt.grid('True',which='both')\n",
    "  # plt.savefig(\"%s/Data_fit_N_%s_dtau_%s_fitting_compare_normal_avg.png\"%(Graph_dir_hf,N,dtau))\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b5168a8a-034a-4de4-8f0e-41dcb14e1580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    N = \"10\"\n",
    "    U = [\"1.00\",\"1.50\",\"2.00\",\"2.50\",\"3.00\",\"3.50\",\"4.00\",\"4.50\",\"5.00\",\"5.50\",\"6.00\",\"6.50\",\"7.00\",\"7.50\",\"8.00\",\"8.50\",\"9.00\",\"9.50\",\"10.00\",\"10.50\",\"11.00\",\"11.50\",\"12.00\"]\n",
    "    Dtau = \"0.05\"\n",
    "    Mu = \"0.00\"\n",
    "    Trot = [\"20\",\"30\",\"40\",\"50\",\"60\"] \n",
    "    \n",
    "    \n",
    "    Text_dir_main_corr_hf = '/Users/roy.369/Documents/Cold_atom_correlators/FHM_Legacy_data/FHM_Roy_data/Text_files/Text_files_N_%s_real_space_correlations_half_filling'%N\n",
    "    Text_dir_main_eqm_hf = '/Users/roy.369/Documents/Cold_atom_correlators/FHM_Legacy_data/FHM_Roy_data/Text_files/Text_files_N_%s_half_filling'%N\n",
    "\n",
    "    \n",
    "    Graph_dir_hf = '/Users/roy.369/Documents/Cold_atom_correlators/FHM_Legacy_data/FHM_Roy_data/Graphs/Graphs_N_%s_half_filling/Graphs_N_%s_dtau_%s_real_space_correlations_normal_averaged/Moment_moment_correlations'%(N,N,Dtau)\n",
    "    if not os.path.exists(Graph_dir_hf):\n",
    "        os.makedirs(Graph_dir_hf)\n",
    "\n",
    "\n",
    "    equal_time_moment_moment_correlation_function_half_filling(Text_dir_main_corr_hf,Text_dir_main_eqm_hf,Graph_dir_hf,N,U,Mu,Dtau,Trot)\n",
    "    #equal_time_moment_moment_correlation_function_doping_U_scaling(Text_dir_main_corr,Text_dir_main_eqm,Graph_dir,N,U,Mu,Dtau,Trot[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6d8b921a-f9e5-4214-bbce-49bf787203bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af7fe14-a038-4ec2-959e-91a4044910d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc100ce-2be9-4311-a300-b07a1b50affd",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_1 = np.asarray([1.2208436724565757, 1.2109181141439205, 1.1910669975186106])\n",
    "N_2 = np.asarray([1.211864406779661,1.2070217917675543, 1.194915254237288])\n",
    "N_3 = np.asarray([1.208816338157447,1.2063950498104907,1.2003418289430996])\n",
    "N_4 = np.asarray([1.197768125317684,1.197768125317684,1.197768125317684])\n",
    "N_4p5 = np.asarray([1.1973365617433411,1.1973365617433411,1.1973365617433411])\n",
    "N_5 = np.asarray([1.191283292978208,1.191283292978208,1.1949152542372878])\n",
    "N_5p5 = np.asarray([\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6f72cf-cd22-4bd4-85dd-7df67c994016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7220704f-5e39-49d0-91d8-996174862b72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47652fc6-1174-4535-ba16-b50d3e018828",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73e044b-04a0-414e-a31d-c60bfa5cb39a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
