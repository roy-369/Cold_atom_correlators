{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7bdbf27f-89de-437e-bf6d-72af2a63782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon May 30 10:11:44 2022\n",
    "\n",
    "@author: roy.369\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "from scipy.interpolate import griddata\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.colorbar\n",
    "from matplotlib import rc\n",
    "mpl.rcParams['axes.linewidth'] = 3\n",
    "import matplotlib as mpl  \n",
    "mpl.rc('font',family='Times New Roman')\n",
    "from matplotlib.pyplot import cm\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "from scipy.optimize import curve_fit\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "from scipy.interpolate import CubicSpline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8a04726-15e0-4ee8-9a83-ae7e344a156d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arr_loc(val,X):\n",
    "   ind = 0\n",
    "   for i in range(len(X)):\n",
    "      if(round(X[i],2) == round(val,2)):\n",
    "         ind = i\n",
    "         break\n",
    "   return ind\n",
    "\n",
    "\n",
    "def power_fit(x,a1,m):\n",
    "    return a1*x**m\n",
    "  \n",
    "def linear_fit(x,a,b):\n",
    "    return a+b*x\n",
    "    \n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return array[idx],idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2df0b97-9923-42db-8bf8-a816cc09191b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_point_upper_half_grid(N):\n",
    "\n",
    "    r_lab = []\n",
    "    r_rel_x = []\n",
    "    r_rel_y = []\n",
    "    x_span = int((int(N))/2)+1\n",
    "    r_pair_1 = 0\n",
    "    for i in range(x_span):\n",
    "        for j in range(x_span):\n",
    "            if(i<=j):\n",
    "              r_lab.append(r_pair_1)  \n",
    "              r_rel_x.append(i)\n",
    "              r_rel_y.append(j)\n",
    "              r_pair_1 = r_pair_1+1\n",
    "\n",
    "    R_relative_1 = np.stack((r_rel_x,r_rel_y),axis = 1)\n",
    "    return R_relative_1,r_pair_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57b4c3d9-ed50-4953-943d-eff05db55ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_point_full_grid(N):\n",
    "\n",
    "    r_lab = []\n",
    "    r_rel_x = []\n",
    "    r_rel_y = []\n",
    "    x_span = int((int(N))/2)+1\n",
    "    r_pair_2 = 0\n",
    "    for i in range(x_span):\n",
    "        for j in range(x_span):\n",
    "              r_lab.append(r_pair_2)\n",
    "              r_rel_x.append(i)\n",
    "              r_rel_y.append(j)\n",
    "              r_pair_2 = r_pair_2+1\n",
    "\n",
    "    R_relative_2 = np.stack((r_rel_x,r_rel_y),axis = 1)\n",
    "    return R_relative_2,r_pair_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "780143b5-e6a1-49d0-bb48-ab945b782e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_point_grid_upper_half_bz(N):\n",
    "\n",
    "    K_lab = []\n",
    "    Kx = []\n",
    "    Ky = []\n",
    "    x_span = int((int(N))/2)+1\n",
    "    k_pair = 0\n",
    "    for i in range(x_span):\n",
    "        for j in range(x_span):\n",
    "            if(i<=j):\n",
    "              K_lab.append(k_pair)  \n",
    "              Kx.append(i)\n",
    "              Ky.append(j)\n",
    "              k_pair = k_pair+1\n",
    "    BZ = np.stack((K_lab,Kx,Ky),axis = 1)\n",
    "    \n",
    "    return BZ,k_pair\n",
    "\n",
    "\n",
    "def k_point_grid_full_bz(N):\n",
    "\n",
    "    K_lab = []\n",
    "    Kx = []\n",
    "    Ky = []\n",
    "    x_span = int((int(N))/2)+1\n",
    "    k_pair = 0\n",
    "    for i in range(x_span):\n",
    "        for j in range(x_span):\n",
    "              K_lab.append(k_pair)\n",
    "              Kx.append(i)\n",
    "              Ky.append(j)\n",
    "              k_pair = k_pair+1\n",
    "    BZ = np.stack((K_lab,Kx,Ky),axis = 1)\n",
    "    \n",
    "    return BZ,k_pair\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6f089b4-7f5f-4bb0-8558-f6b0b571225f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adj_mat_calc(N):\n",
    "\n",
    "    r_grid, r_rel_grid_size = r_point_upper_half_grid(int(N))\n",
    "    r_rel_x = r_grid[:,0]\n",
    "    r_rel_y = r_grid[:,1]\n",
    "\n",
    "    r_2 = np.add(np.power(r_rel_x,2),np.power(r_rel_y,2))\n",
    "    r_2_unq = np.sort(np.unique(r_2))\n",
    "\n",
    "    rx_cord = []\n",
    "    ry_cord = []\n",
    "    r2 = []\n",
    "    rx = np.arange(int(int(N)/2),-1*int(int(N)/2),-1)\n",
    "    ry = np.arange(int(int(N)/2),-1*int(int(N)/2),-1)\n",
    "    for i in range(len(rx)):\n",
    "        for j in range(len(ry)):\n",
    "            rx_cord.append(rx[i])\n",
    "            ry_cord.append(ry[j])\n",
    "            r2.append(rx[i]*rx[i]+ry[j]*ry[j])\n",
    "\n",
    "    #plt.figure()\n",
    "    #plt.scatter(rx_cord,ry_cord,c=r2)\n",
    "\n",
    "    adj_mat = np.zeros(len(r_2_unq))\n",
    "    for i in range(len(r_2_unq)):\n",
    "        count = 0\n",
    "        for i2 in range(len(r2)):\n",
    "            if round(r2[i2],2) == round(r_2_unq[i],2):\n",
    "               count = count+1\n",
    "        adj_mat[i] = count\n",
    "    \n",
    "    return np.stack((r_2_unq,np.asarray(adj_mat)),axis = 1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "195cd798-03ad-41a3-aaa1-113ac4aae94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equal_time_density_density_correlation_function_doping(Text_dir_main_corr,Text_dir_main_eqm,Graph_dir,N,U,Mu,dtau,L):\n",
    "\n",
    "   data_n_zwl = np.array([0.00005,0.002559,0.010701,0.048674,0.160872,0.312911,0.47211,0.622662,0.779081,0.903597,1.009326,1.111819,1.217161])\n",
    "   data_dd_zwl = np.array([0,0,0,0,0,-0.000003,-0.000026,-0.000084,0.000027,-0.000184,-0.000301,-0.00401,-0.010903])\n",
    "   data_hh_zwl = np.array([0,-0.00001,-0.000052,0.001214,-0.001939,-0.008694,-0.017157,-0.01637,-0.008918,-0.001769,0.000079,0.000491,0.000052])\n",
    "   data_hd_zwl = np.array([0,0,0.000001,0.000073,0.000033,0.000177,0.000387,0.001327,0.00133,0.002594,0.003052,0.000845,0.000282])   \n",
    "   data_dd_zwl_err = np.array([0,0,0,0,0,0.000004,0.000018,0.000046,0.000153,0.00011,0.000156,0.001726,0.00209])\n",
    "   data_hh_zwl_err = np.array([0,0.000014,0.000239,0.000496,0.001178,0.001777,0.001991,0.002821,0.001547,0.001526,0.00039,0.000415,0.000427])\n",
    "   data_hd_zwl_err = np.array([0,0,0.000003,0.000045,0.000077,0.000201,0.000215,0.000334,0.000374,0.000592,0.000256,0.00063,0.000757])   \n",
    "    \n",
    "   data_nn_zwl = np.subtract(np.add(data_dd_zwl,data_hh_zwl),2*data_hd_zwl)\n",
    "   data_nn_zwl_err = np.sqrt(np.add(np.add(np.power(data_dd_zwl_err,2),np.power(data_hh_zwl_err,2)),np.power(data_hd_zwl_err,2)))\n",
    "\n",
    "   Adj_list = adj_mat_calc(N)\n",
    "    \n",
    "   r_grid, r_rel_grid_size = r_point_upper_half_grid(N)\n",
    "   r_rel_x = r_grid[:,0]\n",
    "   r_rel_y = r_grid[:,1]\n",
    "\n",
    "   r_2 = np.add(np.power(r_rel_x,2),np.power(r_rel_y,2))\n",
    "   r_2_unq = np.sort(np.unique(r_2))\n",
    "\n",
    "   \n",
    "   Den_Den_conn_corr = np.zeros((len(Mu),len(L),len(r_2_unq)))\n",
    "   Den_Den_conn_corr_std = np.zeros((len(Mu),len(L),len(r_2_unq)))\n",
    "    \n",
    "    \n",
    "   Nden = np.zeros((len(Mu),len(L)))\n",
    "   Nden_std = np.zeros((len(Mu),len(L)))\n",
    "       \n",
    "   Mu_val = np.zeros(len(Mu))\n",
    "    \n",
    "   for j in range(len(Mu)):\n",
    "       Mu_val[j] = float(Mu[j])\n",
    "\n",
    "   T_val = np.zeros(len(L))\n",
    "   for k in range(len(L)):\n",
    "       T_val[k] = 1/(float(dtau)*float(L[k]))\n",
    "       \n",
    "   for j in range(len(Mu)):\n",
    "       for k in range(len(L)):\n",
    "                       \n",
    "           Text_dir_eqm = \"%s/Text_files_N_%s_U_%s_dtau_%s/Mu_%s/dtau_%s_L_%s/Thermodynamic_measurements\"%(Text_dir_main_eqm,N,U,dtau,Mu[j],dtau,L[k])\n",
    "\n",
    "           filename_eqm_avg = '%s/Thermodynamic_measurements_normal_averaged_dictionary_N_%s_U_%s_mu_%s_dtau_%s_L_%s.pkl' %(Text_dir_eqm,N,U,Mu[j],dtau,L[k])\n",
    "           with open(filename_eqm_avg, 'rb') as infile:\n",
    "                sys_measure_avg = pickle.load(infile)\n",
    "\n",
    "           filename_eqm_std = '%s/Thermodynamic_measurements_normal_standard_deviation_dictionary_N_%s_U_%s_mu_%s_dtau_%s_L_%s.pkl' %(Text_dir_eqm,N,U,Mu[j],dtau,L[k])\n",
    "           with open(filename_eqm_std, 'rb') as infile:\n",
    "                sys_measure_std = pickle.load(infile)\n",
    "\n",
    "           Nden[j][k] = sys_measure_avg['Density averaged']\n",
    "           Nden_std[j][k] = sys_measure_std['Density standard deviation']\n",
    "           \n",
    "           Text_dir_den_den_conn_corr = '%s/Text_files_N_%s_U_%s_dtau_%s/Mu_%s/dtau_%s_L_%s/Density_density_connected_correlation_functions'%(Text_dir_main_corr,N,U,dtau,Mu[j],dtau,L[k])\n",
    "\n",
    "           filename_den_den_conn_corr = '%s/Equal_time_Density_Density_connected_correlation_real_space_neighbor_averaged_normal_avg_N_%s_U_%s_mu_%s_dtau_%s_L_%s.dat'%(Text_dir_den_den_conn_corr,N,U,Mu[j],dtau,L[k])\n",
    "           Den_Den_conn_corr[j,k,:],Den_Den_conn_corr_std[j,k,:] = np.loadtxt(filename_den_den_conn_corr,unpack = 'True', usecols = [1,2])\n",
    "    \n",
    " \n",
    "\n",
    "   Den_Den_conn_corr_n0 = np.zeros((len(Mu),len(L)))\n",
    "   Den_Den_conn_corr_n1 = np.zeros((len(Mu),len(L)))\n",
    "   Den_Den_conn_corr_n2 = np.zeros((len(Mu),len(L)))\n",
    "   Den_Den_conn_corr_n3 = np.zeros((len(Mu),len(L)))\n",
    "    \n",
    "   Den_Den_conn_corr_n0_std = np.zeros((len(Mu),len(L)))\n",
    "   Den_Den_conn_corr_n1_std = np.zeros((len(Mu),len(L)))\n",
    "   Den_Den_conn_corr_n2_std = np.zeros((len(Mu),len(L)))\n",
    "   Den_Den_conn_corr_n3_std = np.zeros((len(Mu),len(L)))\n",
    "\n",
    "    \n",
    "   for j in range(len(Mu)):\n",
    "       for k in range(len(L)):\n",
    "\n",
    "\n",
    "           Den_Den_conn_corr_n0[j][k] = Den_Den_conn_corr[j][k][0]\n",
    "           Den_Den_conn_corr_n1[j][k] = Den_Den_conn_corr[j][k][1]\n",
    "           Den_Den_conn_corr_n2[j][k] = Den_Den_conn_corr[j][k][2]\n",
    "           Den_Den_conn_corr_n3[j][k] = Den_Den_conn_corr[j][k][3]\n",
    "           \n",
    "           Den_Den_conn_corr_n0_std[j][k] = Den_Den_conn_corr_std[j][k][0]\n",
    "           Den_Den_conn_corr_n1_std[j][k] = Den_Den_conn_corr_std[j][k][1]\n",
    "           Den_Den_conn_corr_n2_std[j][k] = Den_Den_conn_corr_std[j][k][2]\n",
    "           Den_Den_conn_corr_n3_std[j][k] = Den_Den_conn_corr_std[j][k][3]\n",
    "\n",
    "   color_1 = iter(['red','orange','blue'])\n",
    "   plt.figure(figsize = (25,20))\n",
    "   plt.xticks([0.0,0.5,1.0,1.5,2.0],fontsize = 120)\n",
    "   plt.yticks(fontsize = 120)\n",
    "   for k in range(len(T_val)):\n",
    "       c_1 = next(color_1)\n",
    "       plt.errorbar(Nden[:,k],Den_Den_conn_corr_n1[:,k]*10**3,yerr = Den_Den_conn_corr_n1_std[:,k]*10**3,c=c_1,marker = 'o',markersize = 20, elinewidth = 3, capsize = 5,label = r\"T = %s\"%str(round(T_val[k],3)))\n",
    "   plt.errorbar(data_n_zwl,data_nn_zwl*10**3,yerr = data_nn_zwl_err*10**3,c = 'black',marker = \"^\",markersize = 20, elinewidth = 3, capsize = 5, label = \"Expt\")   \n",
    "   plt.grid(True,which='both')\n",
    "   plt.legend(loc = 'best',ncol = 2, fontsize = 80)\n",
    "   plt.axhline(y = 0, color = 'black', linestyle = 'dashed', linewidth = 2)  \n",
    "   plt.axvline(x = 1, color = 'black', linestyle = 'dashed', linewidth = 2) \n",
    "   plt.tight_layout()\n",
    "   plt.savefig(\"%s/Density_density_correlations_experimental_compare.png\"%Graph_dir)\n",
    "   plt.close()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30df1c5e-9232-4305-854c-d93117715e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equal_time_holon_doublon_correlation_function_doping(Text_dir_main_corr,Text_dir_main_eqm,Graph_dir,N,U,Mu,dtau,L):\n",
    "\n",
    "   data_n_zwl = np.array([0.00005,0.002559,0.010701,0.048674,0.160872,0.312911,0.47211,0.622662,0.779081,0.903597,1.009326,1.111819,1.217161])\n",
    "   data_hd_zwl = np.array([0,0,0.000001,0.000073,0.000033,0.000177,0.000387,0.001327,0.00133,0.002594,0.003052,0.000845,0.000282])\n",
    "   data_hd_zwl_err = np.array([0,0,0.000003,0.000045,0.000077,0.000201,0.000215,0.000334,0.000374,0.000592,0.000256,0.00063,0.000757])\n",
    "   \n",
    "   r_grid, r_rel_grid_size = r_point_upper_half_grid(N)\n",
    "   r_rel_x = r_grid[:,0]\n",
    "   r_rel_y = r_grid[:,1]\n",
    "\n",
    "   r_2 = np.add(np.power(r_rel_x,2),np.power(r_rel_y,2))\n",
    "   r_2_unq = np.sort(np.unique(r_2))\n",
    "\n",
    " \n",
    "\n",
    "   Dbn_Dbn_conn_corr = np.zeros((len(Mu),len(L),len(r_2_unq)))\n",
    "   Dbn_Dbn_conn_corr_std = np.zeros((len(Mu),len(L),len(r_2_unq)))\n",
    "   \n",
    "   Den_Dbn_conn_corr = np.zeros((len(Mu),len(L),len(r_2_unq)))\n",
    "   Den_Dbn_conn_corr_std = np.zeros((len(Mu),len(L),len(r_2_unq)))\n",
    "   \n",
    "   Hln_Dbn_conn_corr = np.zeros((len(Mu),len(L),len(r_2_unq)))\n",
    "   Hln_Dbn_conn_corr_std = np.zeros((len(Mu),len(L),len(r_2_unq)))\n",
    "   \n",
    "   Nden = np.zeros((len(Mu),len(L)))\n",
    "   Nden_std = np.zeros((len(Mu),len(L)))\n",
    "\n",
    "       \n",
    "   T_val = np.zeros(len(L))\n",
    "   for k in range(len(L)):\n",
    "       T_val[k] = 1/(float(dtau)*float(L[k]))\n",
    "       \n",
    "   for j in range(len(Mu)):\n",
    "       for k in range(len(L)):\n",
    "                       \n",
    "           Text_dir_eqm = \"%s/Text_files_N_%s_U_%s_dtau_%s/Mu_%s/dtau_%s_L_%s/Thermodynamic_measurements\"%(Text_dir_main_eqm,N,U,dtau,Mu[j],dtau,L[k])\n",
    "\n",
    "           filename_eqm_avg = '%s/Thermodynamic_measurements_normal_averaged_dictionary_N_%s_U_%s_mu_%s_dtau_%s_L_%s.pkl' %(Text_dir_eqm,N,U,Mu[j],dtau,L[k])\n",
    "           with open(filename_eqm_avg, 'rb') as infile:\n",
    "                sys_measure_avg = pickle.load(infile)\n",
    "\n",
    "           filename_eqm_std = '%s/Thermodynamic_measurements_normal_standard_deviation_dictionary_N_%s_U_%s_mu_%s_dtau_%s_L_%s.pkl' %(Text_dir_eqm,N,U,Mu[j],dtau,L[k])\n",
    "           with open(filename_eqm_std, 'rb') as infile:\n",
    "                sys_measure_std = pickle.load(infile)\n",
    "\n",
    "           Nden[j][k] = sys_measure_avg['Density averaged']\n",
    "           Nden_std[j][k] = sys_measure_std['Density standard deviation']\n",
    "\n",
    "           Text_dir_dbn_dbn_conn_corr = '%s/Text_files_N_%s_U_%s_dtau_%s/Mu_%s/dtau_%s_L_%s/Doublon_doublon_connected_correlation_functions'%(Text_dir_main_corr,N,U,dtau,Mu[j],dtau,L[k])\n",
    "           Text_dir_den_dbn_conn_corr = '%s/Text_files_N_%s_U_%s_dtau_%s/Mu_%s/dtau_%s_L_%s/Density_doublon_connected_correlation_functions'%(Text_dir_main_corr,N,U,dtau,Mu[j],dtau,L[k])\n",
    "\n",
    "\n",
    "           filename_dbn_dbn_conn_corr = '%s/Equal_time_Doublon_doublon_connected_correlation_real_space_neighbor_averaged_normal_avg_N_%s_U_%s_mu_%s_dtau_%s_L_%s.dat'%(Text_dir_dbn_dbn_conn_corr,N,U,Mu[j],dtau,L[k])\n",
    "           Dbn_Dbn_conn_corr[j,k,:],Dbn_Dbn_conn_corr_std[j,k,:] = np.loadtxt(filename_dbn_dbn_conn_corr,unpack = 'True', usecols = [1,2])\n",
    "\n",
    "           filename_den_dbn_conn_corr = '%s/Equal_time_Density_Doublon_connected_correlation_real_space_neighbor_averaged_normal_avg_N_%s_U_%s_mu_%s_dtau_%s_L_%s.dat'%(Text_dir_den_dbn_conn_corr,N,U,Mu[j],dtau,L[k])\n",
    "           Den_Dbn_conn_corr[j,k,:],Den_Dbn_conn_corr_std[j,k,:] = np.loadtxt(filename_den_dbn_conn_corr,unpack = 'True', usecols = [1,2])\n",
    "\n",
    "\n",
    "           Hln_Dbn_conn_corr[j,k,:] = np.subtract(Dbn_Dbn_conn_corr[j,k,:],Den_Dbn_conn_corr[j,k,:])\n",
    "           Hln_Dbn_conn_corr_std[j,k,:] = np.sqrt(np.add(np.power(Dbn_Dbn_conn_corr_std[j,k,:],2),np.power(Den_Dbn_conn_corr_std[j,k,:],2)))\n",
    "\n",
    "\n",
    "    \n",
    "   Hln_Dbn_conn_corr_n0 = np.zeros((len(Mu),len(L)))\n",
    "   Hln_Dbn_conn_corr_n1 = np.zeros((len(Mu),len(L)))\n",
    "   Hln_Dbn_conn_corr_n2 = np.zeros((len(Mu),len(L)))\n",
    "   Hln_Dbn_conn_corr_n3 = np.zeros((len(Mu),len(L)))\n",
    "    \n",
    "   Hln_Dbn_conn_corr_n0_std = np.zeros((len(Mu),len(L)))\n",
    "   Hln_Dbn_conn_corr_n1_std = np.zeros((len(Mu),len(L)))\n",
    "   Hln_Dbn_conn_corr_n2_std = np.zeros((len(Mu),len(L)))\n",
    "   Hln_Dbn_conn_corr_n3_std = np.zeros((len(Mu),len(L)))\n",
    "\n",
    "\n",
    "   for j in range(len(Mu)):\n",
    "       for k in range(len(L)):\n",
    "\n",
    "           Hln_Dbn_conn_corr_n0[j][k] = Hln_Dbn_conn_corr[j][k][0]\n",
    "           Hln_Dbn_conn_corr_n1[j][k] = Hln_Dbn_conn_corr[j][k][1]\n",
    "           Hln_Dbn_conn_corr_n2[j][k] = Hln_Dbn_conn_corr[j][k][2]\n",
    "           Hln_Dbn_conn_corr_n3[j][k] = Hln_Dbn_conn_corr[j][k][3]\n",
    "           \n",
    "           Hln_Dbn_conn_corr_n0_std[j][k] = Hln_Dbn_conn_corr_std[j][k][0]\n",
    "           Hln_Dbn_conn_corr_n1_std[j][k] = Hln_Dbn_conn_corr_std[j][k][1]\n",
    "           Hln_Dbn_conn_corr_n2_std[j][k] = Hln_Dbn_conn_corr_std[j][k][2]\n",
    "           Hln_Dbn_conn_corr_n3_std[j][k] = Hln_Dbn_conn_corr_std[j][k][3]\n",
    "\n",
    "   color_1 = iter(['red','orange','blue'])\n",
    "   plt.figure(figsize = (25,20))\n",
    "   plt.xticks([0.0,0.5,1.0,1.5,2.0],fontsize = 120)\n",
    "   plt.yticks([0.000,1,2,3],fontsize = 120)\n",
    "   for k in range(len(T_val)):\n",
    "       c_1 = next(color_1)\n",
    "       plt.errorbar(Nden[:,k],Hln_Dbn_conn_corr_n1[:,k]*10**3,yerr = Hln_Dbn_conn_corr_n1_std[:,k]*10**3,c=c_1,marker = 'o',markersize = 20, elinewidth = 3, capsize = 5,label = r\"T = %s\"%str(round(T_val[k],3)))\n",
    "   plt.errorbar(data_n_zwl,data_hd_zwl*10**3,yerr = data_hd_zwl_err*10**3,c = 'black',marker = \"^\",markersize = 20, elinewidth = 3, capsize = 5, label = \"Expt\")   \n",
    "   plt.grid(True,which='both')\n",
    "   plt.legend(loc = 'best',fontsize = 80)\n",
    "   plt.axhline(y = 0, color = 'black', linestyle = 'dashed', linewidth = 2)  \n",
    "   plt.axvline(x = 1, color = 'black', linestyle = 'dashed', linewidth = 2) \n",
    "   plt.tight_layout()\n",
    "   plt.savefig(\"%s/Holon_doublon_correlations_experimental_compare.png\"%Graph_dir)\n",
    "   plt.close()          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f42655b-3691-4851-813a-60de3f8a2e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equal_time_moment_moment_correlation_function_doping(Text_dir_main_corr,Text_dir_main_eqm,Graph_dir,N,U,Mu,dtau,L):\n",
    "\n",
    "   data_n_zwl = np.array([0.00005,0.002559,0.010701,0.048674,0.160872,0.312911,0.47211,0.622662,0.779081,0.903597,1.009326,1.111819,1.217161])\n",
    "   data_mm_zwl = np.array([0,-0.00001,-0.000049,0.001361,-0.001873,-0.008343,-0.016409,-0.013801,-0.00623,0.003235,0.005881,-0.001829,-0.010288])\n",
    "   data_mm_zwl_err = np.array([0,0.000014,0.000238,0.000474,0.001127,0.001764,0.001946,0.002866,0.001595,0.001606,0.000776,0.002612,0.002776])\n",
    "\n",
    "   Adj_list = adj_mat_calc(N)\n",
    "    \n",
    "   r_grid, r_rel_grid_size = r_point_upper_half_grid(N)\n",
    "   r_rel_x = r_grid[:,0]\n",
    "   r_rel_y = r_grid[:,1]\n",
    "\n",
    "   r_2 = np.add(np.power(r_rel_x,2),np.power(r_rel_y,2))\n",
    "   r_2_unq = np.sort(np.unique(r_2))\n",
    "\n",
    "   M2_M2_conn_corr = np.zeros((len(Mu),len(L),len(r_2_unq)))\n",
    "   M2_M2_conn_corr_std = np.zeros((len(Mu),len(L),len(r_2_unq)))\n",
    "  \n",
    "   Nden = np.zeros((len(Mu),len(L)))\n",
    "   Nden_std = np.zeros((len(Mu),len(L)))\n",
    "       \n",
    "   T_val = np.zeros(len(L))\n",
    "   for k in range(len(L)):\n",
    "       T_val[k] = 1/(float(dtau)*float(L[k]))\n",
    "\n",
    "    \n",
    "   for j in range(len(Mu)):\n",
    "       for k in range(len(L)):\n",
    "               \n",
    "           Text_dir_eqm = \"%s/Text_files_N_%s_U_%s_dtau_%s/Mu_%s/dtau_%s_L_%s/Thermodynamic_measurements\"%(Text_dir_main_eqm,N,U,dtau,Mu[j],dtau,L[k])\n",
    "\n",
    "           filename_eqm_avg = '%s/Thermodynamic_measurements_normal_averaged_dictionary_N_%s_U_%s_mu_%s_dtau_%s_L_%s.pkl' %(Text_dir_eqm,N,U,Mu[j],dtau,L[k])\n",
    "           with open(filename_eqm_avg, 'rb') as infile:\n",
    "                sys_measure_avg = pickle.load(infile)\n",
    "\n",
    "           filename_eqm_std = '%s/Thermodynamic_measurements_normal_standard_deviation_dictionary_N_%s_U_%s_mu_%s_dtau_%s_L_%s.pkl' %(Text_dir_eqm,N,U,Mu[j],dtau,L[k])\n",
    "           with open(filename_eqm_std, 'rb') as infile:\n",
    "                sys_measure_std = pickle.load(infile)\n",
    "\n",
    "           Nden[j][k] = sys_measure_avg['Density averaged']\n",
    "           Nden_std[j][k] = sys_measure_std['Density standard deviation']\n",
    "              \n",
    "           Text_dir_m2_m2_conn_corr = '%s/Text_files_N_%s_U_%s_dtau_%s/Mu_%s/dtau_%s_L_%s/Moment_moment_connected_correlation_functions'%(Text_dir_main_corr,N,U,dtau,Mu[j],dtau,L[k])\n",
    "\n",
    "           filename_m2_m2_conn_corr = '%s/Equal_time_Moment_Moment_connected_correlation_real_space_neighbor_averaged_normal_avg_N_%s_U_%s_mu_%s_dtau_%s_L_%s.dat'%(Text_dir_m2_m2_conn_corr,N,U,Mu[j],dtau,L[k])\n",
    "           M2_M2_conn_corr[j,k,:],M2_M2_conn_corr_std[j,k,:] = np.loadtxt(filename_m2_m2_conn_corr,unpack = 'True', usecols = [1,2])\n",
    "\n",
    "\n",
    "   M2_M2_conn_corr_n0 = np.zeros((len(Mu),len(L)))\n",
    "   M2_M2_conn_corr_n1 = np.zeros((len(Mu),len(L)))\n",
    "   M2_M2_conn_corr_n2 = np.zeros((len(Mu),len(L)))\n",
    "   M2_M2_conn_corr_n3 = np.zeros((len(Mu),len(L)))\n",
    "    \n",
    "   M2_M2_conn_corr_n0_std = np.zeros((len(Mu),len(L)))\n",
    "   M2_M2_conn_corr_n1_std = np.zeros((len(Mu),len(L)))\n",
    "   M2_M2_conn_corr_n2_std = np.zeros((len(Mu),len(L)))\n",
    "   M2_M2_conn_corr_n3_std = np.zeros((len(Mu),len(L)))\n",
    "\n",
    "\n",
    "   for j in range(len(Mu)):\n",
    "       for k in range(len(L)):\n",
    "\n",
    "           M2_M2_conn_corr_n0[j][k] = M2_M2_conn_corr[j][k][0]\n",
    "           M2_M2_conn_corr_n1[j][k] = M2_M2_conn_corr[j][k][1]\n",
    "           M2_M2_conn_corr_n2[j][k] = M2_M2_conn_corr[j][k][2]\n",
    "           M2_M2_conn_corr_n3[j][k] = M2_M2_conn_corr[j][k][3]\n",
    "\n",
    "   color_1 = iter(['red','orange','blue'])\n",
    "   plt.figure(figsize = (25,20))\n",
    "   plt.xticks([0.0,0.5,1.0,1.5,2.0],fontsize = 120)\n",
    "   plt.yticks(fontsize = 120)\n",
    "   for k in range(len(T_val)):\n",
    "       c_1 = next(color_1)\n",
    "       plt.errorbar(Nden[:,k],M2_M2_conn_corr_n1[:,k]*10**3,yerr = M2_M2_conn_corr_n1_std[:,k]*10**3,c=c_1,marker = 'o',markersize = 20, elinewidth = 3, capsize = 5,label = r\"T = %s\"%str(round(T_val[k],3)))\n",
    "   plt.errorbar(data_n_zwl,data_mm_zwl*10**3,yerr = data_mm_zwl_err*10**3,c = 'black',marker = \"^\",markersize = 20, elinewidth = 3, capsize = 5, label = \"Expt\")   \n",
    "   plt.grid(True,which='both')\n",
    "   plt.axhline(y = 0, color = 'black', linestyle = 'dashed', linewidth = 2)  \n",
    "   plt.axvline(x = 1, color = 'black', linestyle = 'dashed', linewidth = 2)  \n",
    "   plt.legend(loc = 'best',fontsize = 80)\n",
    "   plt.tight_layout()\n",
    "   plt.savefig(\"%s/Moment_moment_correlations_experimental_compare.png\"%Graph_dir)\n",
    "   plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d2743b6-c999-4389-a554-198a3bbf57df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equal_time_holon_holon_correlation_function_doping(Text_dir_main_corr,Text_dir_main_eqm,Graph_dir,N,U,Mu,dtau,L):\n",
    "\n",
    "   data_n_zwl = np.array([0.00005,0.002559,0.010701,0.048674,0.160872,0.312911,0.47211,0.622662,0.779081,0.903597,1.009326,1.111819,1.217161])\n",
    "   data_hh_zwl = np.array([0,-0.00001,-0.000052,0.001214,-0.001939,-0.008694,-0.017157,-0.01637,-0.008918,-0.001769,0.000079,0.000491,0.000052])\n",
    "   data_hh_zwl_err = np.array([0,0.000014,0.000239,0.000496,0.001178,0.001777,0.001991,0.002821,0.001547,0.001526,0.00039,0.000415,0.000427])\n",
    "\n",
    "\n",
    "   Adj_list = adj_mat_calc(N)\n",
    "    \n",
    "   r_grid, r_rel_grid_size = r_point_upper_half_grid(N)\n",
    "   r_rel_x = r_grid[:,0]\n",
    "   r_rel_y = r_grid[:,1]\n",
    "\n",
    "   r_2 = np.add(np.power(r_rel_x,2),np.power(r_rel_y,2))\n",
    "   r_2_unq = np.sort(np.unique(r_2))\n",
    "\n",
    "   Den_Den_conn_corr = np.zeros((len(Mu),len(L),len(r_2_unq)))\n",
    "   Den_Den_conn_corr_std = np.zeros((len(Mu),len(L),len(r_2_unq)))\n",
    "   \n",
    "   Den_Dbn_conn_corr = np.zeros((len(Mu),len(L),len(r_2_unq)))\n",
    "   Den_Dbn_conn_corr_std = np.zeros((len(Mu),len(L),len(r_2_unq)))\n",
    "\n",
    "   Dbn_Dbn_conn_corr = np.zeros((len(Mu),len(L),len(r_2_unq)))\n",
    "   Dbn_Dbn_conn_corr_std = np.zeros((len(Mu),len(L),len(r_2_unq)))\n",
    "    \n",
    "   Hln_Hln_conn_corr = np.zeros((len(Mu),len(L),len(r_2_unq)))\n",
    "   Hln_Hln_conn_corr_std = np.zeros((len(Mu),len(L),len(r_2_unq)))   \n",
    "   \n",
    "   Nden = np.zeros((len(Mu),len(L)))\n",
    "   Nden_std = np.zeros((len(Mu),len(L)))\n",
    "\n",
    "       \n",
    "   for j in range(len(Mu)):\n",
    "       for k in range(len(L)):\n",
    "                \n",
    "           Text_dir_eqm = \"%s/Text_files_N_%s_U_%s_dtau_%s/Mu_%s/dtau_%s_L_%s/Thermodynamic_measurements\"%(Text_dir_main_eqm,N,U,dtau,Mu[j],dtau,L[k])\n",
    "\n",
    "           filename_eqm_avg = '%s/Thermodynamic_measurements_normal_averaged_dictionary_N_%s_U_%s_mu_%s_dtau_%s_L_%s.pkl' %(Text_dir_eqm,N,U,Mu[j],dtau,L[k])\n",
    "           with open(filename_eqm_avg, 'rb') as infile:\n",
    "                    sys_measure_avg = pickle.load(infile)\n",
    "\n",
    "           filename_eqm_std = '%s/Thermodynamic_measurements_normal_standard_deviation_dictionary_N_%s_U_%s_mu_%s_dtau_%s_L_%s.pkl' %(Text_dir_eqm,N,U,Mu[j],dtau,L[k])\n",
    "           with open(filename_eqm_std, 'rb') as infile:\n",
    "                    sys_measure_std = pickle.load(infile)\n",
    "\n",
    "           Nden[j][k] = sys_measure_avg['Density averaged']\n",
    "           Nden_std[j][k] = sys_measure_std['Density standard deviation']  \n",
    "               \n",
    "           Text_dir_den_den_corr = '%s/Text_files_N_%s_U_%s_dtau_%s/Mu_%s/dtau_%s_L_%s/Density_density_connected_correlation_functions'%(Text_dir_main_corr,N,U,dtau,Mu[j],dtau,L[k])\n",
    "           \n",
    "           filename_den_den_corr = '%s/Equal_time_Density_Density_connected_correlation_real_space_neighbor_averaged_normal_avg_N_%s_U_%s_mu_%s_dtau_%s_L_%s.dat'%(Text_dir_den_den_corr,N,U,Mu[j],dtau,L[k])\n",
    "           Den_Den_conn_corr[j,k,:],Den_Den_conn_corr_std[j,k,:] = np.loadtxt(filename_den_den_corr,unpack = 'True', usecols = [1,2])\n",
    "\n",
    "           Text_dir_dbn_dbn_corr = '%s/Text_files_N_%s_U_%s_dtau_%s/Mu_%s/dtau_%s_L_%s/Doublon_doublon_connected_correlation_functions'%(Text_dir_main_corr,N,U,dtau,Mu[j],dtau,L[k])\n",
    "           \n",
    "           filename_dbn_dbn_corr = '%s/Equal_time_Doublon_Doublon_connected_correlation_real_space_neighbor_averaged_normal_avg_N_%s_U_%s_mu_%s_dtau_%s_L_%s.dat'%(Text_dir_dbn_dbn_corr,N,U,Mu[j],dtau,L[k])\n",
    "           Dbn_Dbn_conn_corr[j,k,:],Dbn_Dbn_conn_corr_std[j,k,:] = np.loadtxt(filename_dbn_dbn_corr,unpack = 'True', usecols = [1,2])\n",
    "\n",
    "           Text_dir_den_dbn_corr = '%s/Text_files_N_%s_U_%s_dtau_%s/Mu_%s/dtau_%s_L_%s/Density_doublon_connected_correlation_functions'%(Text_dir_main_corr,N,U,dtau,Mu[j],dtau,L[k])\n",
    "           \n",
    "           filename_den_dbn_corr = '%s/Equal_time_Density_Doublon_connected_correlation_real_space_neighbor_averaged_normal_avg_N_%s_U_%s_mu_%s_dtau_%s_L_%s.dat'%(Text_dir_den_dbn_corr,N,U,Mu[j],dtau,L[k])\n",
    "           Den_Dbn_conn_corr[j,k,:],Den_Dbn_conn_corr_std[j,k,:] = np.loadtxt(filename_den_dbn_corr,unpack = 'True', usecols = [1,2])\n",
    "\n",
    "           Hln_Hln_conn_corr[j,k,:] = np.subtract(np.add(Den_Den_conn_corr[j,k,:],Dbn_Dbn_conn_corr[j,k,:]),2*Den_Dbn_conn_corr[j,k,:])\n",
    "           Hln_Hln_conn_corr_std[j,k,:] = np.sqrt(np.add(np.power(Den_Den_conn_corr_std[j,k,:],2),np.add(np.power(Dbn_Dbn_conn_corr_std[j,k,:],2),4*np.power(Den_Dbn_conn_corr_std[j,k,:],2))))\n",
    "    \n",
    "\n",
    "   T_val = np.zeros(len(L))\n",
    "   for k in range(len(L)):\n",
    "       T_val[k] = 1/(float(dtau)*float(L[k]))\n",
    "\n",
    "    \n",
    "   Hln_Hln_conn_corr_n0 = np.zeros((len(Mu),len(L)))\n",
    "   Hln_Hln_conn_corr_n1 = np.zeros((len(Mu),len(L)))\n",
    "   Hln_Hln_conn_corr_n2 = np.zeros((len(Mu),len(L)))\n",
    "   Hln_Hln_conn_corr_n3 = np.zeros((len(Mu),len(L)))\n",
    "    \n",
    "   Hln_Hln_conn_corr_n0_std = np.zeros((len(Mu),len(L)))\n",
    "   Hln_Hln_conn_corr_n1_std = np.zeros((len(Mu),len(L)))\n",
    "   Hln_Hln_conn_corr_n2_std = np.zeros((len(Mu),len(L)))\n",
    "   Hln_Hln_conn_corr_n3_std = np.zeros((len(Mu),len(L)))\n",
    " \n",
    "    \n",
    "   for j in range(len(Mu)):\n",
    "       for k in range(len(L)):\n",
    "\n",
    "           Hln_Hln_conn_corr_n0[j][k] = Hln_Hln_conn_corr[j][k][0]\n",
    "           Hln_Hln_conn_corr_n1[j][k] = Hln_Hln_conn_corr[j][k][1]\n",
    "           Hln_Hln_conn_corr_n2[j][k] = Hln_Hln_conn_corr[j][k][2]\n",
    "           Hln_Hln_conn_corr_n3[j][k] = Hln_Hln_conn_corr[j][k][3]\n",
    "           \n",
    "           Hln_Hln_conn_corr_n0_std[j][k] = Hln_Hln_conn_corr_std[j][k][0]\n",
    "           Hln_Hln_conn_corr_n1_std[j][k] = Hln_Hln_conn_corr_std[j][k][1]\n",
    "           Hln_Hln_conn_corr_n2_std[j][k] = Hln_Hln_conn_corr_std[j][k][2]\n",
    "           Hln_Hln_conn_corr_n3_std[j][k] = Hln_Hln_conn_corr_std[j][k][3]\n",
    "\n",
    "   color_1 = iter(['red','orange','blue'])\n",
    "   plt.figure(figsize = (25,20))\n",
    "   plt.xticks([0.0,0.5,1.0,1.5,2.0],fontsize = 120)\n",
    "   plt.yticks(fontsize = 120)\n",
    "   for k in range(len(T_val)):\n",
    "       c_1 = next(color_1)\n",
    "       plt.errorbar(Nden[:,k],Hln_Hln_conn_corr_n1[:,k]*10**3,yerr = Hln_Hln_conn_corr_n1_std[:,k]*10**3,c=c_1,marker = 'o',markersize = 20, elinewidth = 3, capsize = 5,label = r\"T = %s\"%str(round(T_val[k],3)))\n",
    "   plt.errorbar(data_n_zwl,data_hh_zwl*10**3,yerr = data_hh_zwl_err*10**3,c = 'black',marker = \"^\",markersize = 20, elinewidth = 3, capsize = 5, label = \"Expt\")   \n",
    "   plt.grid(True,which='both')\n",
    "   plt.legend(loc = 'best',fontsize = 80)\n",
    "   plt.axhline(y = 0, color = 'black', linestyle = 'dashed', linewidth = 2)  \n",
    "   plt.axvline(x = 1, color = 'black', linestyle = 'dashed', linewidth = 2) \n",
    "   plt.tight_layout()\n",
    "   plt.savefig(\"%s/Holon_holon_correlations_experimental_compare.png\"%Graph_dir)\n",
    "   plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5168a8a-034a-4de4-8f0e-41dcb14e1580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    N = \"10\"\n",
    "    Dtau = \"0.05\"\n",
    "\n",
    "    U=\"11.8\" #,\"4.50\",\"4.60\",\"4.70\"]\n",
    "    Mu = [\"-14.00\",\"-13.50\",\"-13.00\",\"-12.50\",\"-12.00\",\"-11.50\",\"-11.00\",\"-10.50\",\"-10.00\",\"-9.50\",\"-9.00\",\"-8.50\",\"-8.00\",\"-7.50\",\"-7.00\",\n",
    "          \"-6.50\",\"-6.00\",\"-5.50\",\"-5.00\",\"-4.50\",\"-4.00\",\"-3.50\",\"-3.00\",\"-2.50\",\"-2.00\",\"-1.50\",\"-1.00\",\"-0.50\",\"0.00\",\"0.50\",\"1.00\",\"1.50\",\n",
    "          \"2.00\",\"2.50\",\"3.00\",\"3.50\",\"4.00\",\"4.50\",\"5.00\",\"5.50\",\"6.00\",\"6.50\",\"7.00\",\"7.50\",\"8.00\",\"8.50\",\"9.00\",\"9.50\",\"10.00\"]\n",
    "    Trot = [\"12\",\"14\",\"16\"]\n",
    "\n",
    "    Text_dir_main_corr = '/Users/roy.369/Documents/Cold_atom_correlators/FHM_Legacy_data/FHM_Roy_data/Text_files/Text_files_N_%s_real_space_correlations'%N\n",
    "    Text_dir_main_eqm = '/Users/roy.369/Documents/Cold_atom_correlators/FHM_Legacy_data/FHM_Roy_data/Text_files/Text_files_N_%s'%N\n",
    "    \n",
    "    Graph_dir = '/Users/roy.369/Documents/Cold_atom_correlators/FHM_Legacy_data/FHM_Roy_data/Graphs/Graphs_N_%s_experimental_compare/Graphs_N_%s_dtau_%s_real_space_correlations_normal_averaged_experimental_compare'%(N,N,Dtau)\n",
    "    if not os.path.exists(Graph_dir):\n",
    "        os.makedirs(Graph_dir)\n",
    "        \n",
    "    equal_time_density_density_correlation_function_doping(Text_dir_main_corr,Text_dir_main_eqm,Graph_dir,N,U,Mu,Dtau,Trot)\n",
    "    equal_time_holon_doublon_correlation_function_doping(Text_dir_main_corr,Text_dir_main_eqm,Graph_dir,N,U,Mu,Dtau,Trot)\n",
    "    equal_time_moment_moment_correlation_function_doping(Text_dir_main_corr,Text_dir_main_eqm,Graph_dir,N,U,Mu,Dtau,Trot)\n",
    "    equal_time_holon_holon_correlation_function_doping(Text_dir_main_corr,Text_dir_main_eqm,Graph_dir,N,U,Mu,Dtau,Trot)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d8b921a-f9e5-4214-bbce-49bf787203bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af7fe14-a038-4ec2-959e-91a4044910d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198fc144-24e0-4144-b4bd-79f3cf7b4b82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af452001-065c-4df2-8b3a-ee76bd16128c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adf15d9-74d6-46dd-9223-4e35b857f5bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
