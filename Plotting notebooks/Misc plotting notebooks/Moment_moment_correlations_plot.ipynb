{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7bdbf27f-89de-437e-bf6d-72af2a63782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon May 30 10:11:44 2022\n",
    "\n",
    "@author: roy.369\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "from scipy.interpolate import griddata\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.colorbar\n",
    "from matplotlib import rc\n",
    "mpl.rcParams['axes.linewidth'] = 3\n",
    "import matplotlib as mpl  \n",
    "mpl.rc('font',family='Times New Roman')\n",
    "from matplotlib.pyplot import cm\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "from scipy.optimize import curve_fit\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "from scipy.interpolate import CubicSpline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8a04726-15e0-4ee8-9a83-ae7e344a156d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arr_loc(val,X):\n",
    "   ind = 0\n",
    "   for i in range(len(X)):\n",
    "      if(round(X[i],2) == round(val,2)):\n",
    "         ind = i\n",
    "         break\n",
    "   return ind\n",
    "\n",
    "\n",
    "def power_fit(x,a1,m):\n",
    "    return a1*x**m\n",
    "  \n",
    "def linear_fit(x,a,b):\n",
    "    return a+b*x\n",
    "    \n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return array[idx],idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2df0b97-9923-42db-8bf8-a816cc09191b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_point_upper_half_grid(N):\n",
    "\n",
    "    r_lab = []\n",
    "    r_rel_x = []\n",
    "    r_rel_y = []\n",
    "    x_span = int((int(N))/2)+1\n",
    "    r_pair_1 = 0\n",
    "    for i in range(x_span):\n",
    "        for j in range(x_span):\n",
    "            if(i<=j):\n",
    "              r_lab.append(r_pair_1)  \n",
    "              r_rel_x.append(i)\n",
    "              r_rel_y.append(j)\n",
    "              r_pair_1 = r_pair_1+1\n",
    "\n",
    "    R_relative_1 = np.stack((r_rel_x,r_rel_y),axis = 1)\n",
    "    return R_relative_1,r_pair_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57b4c3d9-ed50-4953-943d-eff05db55ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_point_full_grid(N):\n",
    "\n",
    "    r_lab = []\n",
    "    r_rel_x = []\n",
    "    r_rel_y = []\n",
    "    x_span = int((int(N))/2)+1\n",
    "    r_pair_2 = 0\n",
    "    for i in range(x_span):\n",
    "        for j in range(x_span):\n",
    "              r_lab.append(r_pair_2)\n",
    "              r_rel_x.append(i)\n",
    "              r_rel_y.append(j)\n",
    "              r_pair_2 = r_pair_2+1\n",
    "\n",
    "    R_relative_2 = np.stack((r_rel_x,r_rel_y),axis = 1)\n",
    "    return R_relative_2,r_pair_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "780143b5-e6a1-49d0-bb48-ab945b782e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_point_grid_upper_half_bz(N):\n",
    "\n",
    "    K_lab = []\n",
    "    Kx = []\n",
    "    Ky = []\n",
    "    x_span = int((int(N))/2)+1\n",
    "    k_pair = 0\n",
    "    for i in range(x_span):\n",
    "        for j in range(x_span):\n",
    "            if(i<=j):\n",
    "              K_lab.append(k_pair)  \n",
    "              Kx.append(i)\n",
    "              Ky.append(j)\n",
    "              k_pair = k_pair+1\n",
    "    BZ = np.stack((K_lab,Kx,Ky),axis = 1)\n",
    "    \n",
    "    return BZ,k_pair\n",
    "\n",
    "\n",
    "def k_point_grid_full_bz(N):\n",
    "\n",
    "    K_lab = []\n",
    "    Kx = []\n",
    "    Ky = []\n",
    "    x_span = int((int(N))/2)+1\n",
    "    k_pair = 0\n",
    "    for i in range(x_span):\n",
    "        for j in range(x_span):\n",
    "              K_lab.append(k_pair)\n",
    "              Kx.append(i)\n",
    "              Ky.append(j)\n",
    "              k_pair = k_pair+1\n",
    "    BZ = np.stack((K_lab,Kx,Ky),axis = 1)\n",
    "    \n",
    "    return BZ,k_pair\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6f089b4-7f5f-4bb0-8558-f6b0b571225f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adj_mat_calc(N):\n",
    "\n",
    "    r_grid, r_rel_grid_size = r_point_full_grid(int(N))\n",
    "    r_rel_x = r_grid[:,0]\n",
    "    r_rel_y = r_grid[:,1]\n",
    "\n",
    "    r_2 = np.add(np.power(r_rel_x,2),np.power(r_rel_y,2))\n",
    "    r_2_unq = np.sort(np.unique(r_2))\n",
    "\n",
    "    rx_cord = []\n",
    "    ry_cord = []\n",
    "    r2 = []\n",
    "    rx = np.arange(int(int(N)/2),-1*int(int(N)/2),-1)\n",
    "    ry = np.arange(int(int(N)/2),-1*int(int(N)/2),-1)\n",
    "    for i in range(len(rx)):\n",
    "        for j in range(len(ry)):\n",
    "            rx_cord.append(rx[i])\n",
    "            ry_cord.append(ry[j])\n",
    "            r2.append(rx[i]*rx[i]+ry[j]*ry[j])\n",
    "\n",
    "    #plt.figure()\n",
    "    #plt.scatter(rx_cord,ry_cord,c=r2)\n",
    "\n",
    "    adj_mat = np.zeros(len(r_2_unq))\n",
    "    for i in range(len(r_2_unq)):\n",
    "        count = 0\n",
    "        for i2 in range(len(r2)):\n",
    "            if round(r2[i2],2) == round(r_2_unq[i],2):\n",
    "               count = count+1\n",
    "        adj_mat[i] = count\n",
    "    \n",
    "    return np.stack((r_2_unq,np.asarray(adj_mat)),axis = 1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e5e7a51-f813-4b7c-b5fd-0a7ecd0a1030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_func_multiple_beta_hf(N,u_val,mu,dtau,trot,plot_title,plot_x_label,plot_y_label,x_val,y_val,y_val_err,plot_name):\n",
    "\n",
    "   color_1 = iter(cm.gnuplot(np.linspace(0, 1, len(trot)+1)))\n",
    "   plt.figure(figsize = (28,20))\n",
    "   #plt.title(plot_title,fontsize = 60)\n",
    "   plt.xticks(fontsize = 80)\n",
    "   plt.yticks([0.010,0.015,0.020,0.025,0.030],fontsize = 80)\n",
    "   #plt.xscale('log')\n",
    "   #plt.yscale('log') \n",
    "   #plt.ylabel(plot_y_label,fontsize = 60)\n",
    "   #plt.xlabel(plot_x_label,fontsize = 60)\n",
    "   #U_val = np.linspace(1.0,10.0,num=101)\n",
    "   #Hd_fit = 0.55*np.power(U_val,-2) \n",
    "   for jj in range(len(trot)):\n",
    "       c_1 = next(color_1)\n",
    "       beta = (float(dtau))*(float(trot[jj]))\n",
    "       T = round(1/beta,2)\n",
    "       plt.errorbar(x_val,y_val[:,jj],yerr = y_val_err[:,jj],c=c_1,marker = 'o',markersize = 20, elinewidth = 3, capsize = 5,label = r\"T = %s\"%str(T))\n",
    "   #plt.plot(U_val,Hd_fit,linestyle = 'dashed',color=  'black',linewidth = 3)\n",
    "   #plt.ylim(top=0.1)  \n",
    "   plt.grid(True,which='both')\n",
    "   #plt.axvspan(3.5, 4.5, facecolor='r', alpha=0.2)\n",
    "   #plt.axvspan(4.0, 6.0, facecolor='b', alpha=0.2)\n",
    "   plt.legend(loc='best',fontsize = 60) \n",
    "   plt.tight_layout() \n",
    "   plt.savefig(plot_name)\n",
    "   plt.close()\n",
    "\n",
    "def plot_func_multiple_U_hf(N,u_val,mu,dtau,trot,plot_title,plot_x_label,plot_y_label,x_val,y_val,y_val_err,plot_name):\n",
    "\n",
    "   color_1 = iter(['blue','darkgreen','olive','darkgoldenrod','orange','red'])\n",
    "   plt.figure(figsize = (25,20))\n",
    "   #plt.title(plot_title,fontsize = 60)\n",
    "   plt.yticks([0.01,0.02,0.03],fontsize = 80)\n",
    "   plt.xticks(fontsize = 80)\n",
    "   #plt.xscale('log')\n",
    "   #plt.yscale('log') \n",
    "   #plt.ylabel(plot_y_label,fontsize = 60)\n",
    "   #plt.xlabel(plot_x_label,fontsize = 60)\n",
    "   #U_val = np.linspace(1.0,10.0,num=101)\n",
    "   U_val =[\"1.0\",\"4.0\",\"5.0\",\"6.0\",\"8.0\",\"10.0\"] \n",
    "   #Hd_fit = 0.55*np.power(U_val,-2) \n",
    "   for i in range(len(u_val)):\n",
    "       c_1 = next(color_1)\n",
    "       plt.errorbar(x_val,y_val[i,:],yerr = y_val_err[i,:],c=c_1,marker = 'o',markersize = 20, elinewidth = 3, capsize = 5,label = r\"U = %s\"%str(U_val[i]))\n",
    "   #plt.plot(U_val,Hd_fit,linestyle = 'dashed',color=  'black',linewidth = 3)\n",
    "   #plt.ylim(top=0.1)  \n",
    "   plt.grid(True,which='both')\n",
    "   #plt.axvspan(3.5, 4.5, facecolor='r', alpha=0.2)\n",
    "   #plt.axvspan(4.0, 6.0, facecolor='b', alpha=0.2)\n",
    "   plt.legend(loc='best',ncol=2,fontsize = 60) \n",
    "   plt.tight_layout() \n",
    "   plt.savefig(plot_name)\n",
    "   plt.close()\n",
    "\n",
    "\n",
    "def plot_func_multiple_beta_doping(N,u_val,mu,dtau,trot,plot_title,plot_x_label,plot_y_label,x_val,y_val,y_val_err,plot_name):\n",
    "\n",
    "   color_1 = iter(cm.gnuplot(np.linspace(0, 1, len(trot)+1)))\n",
    "   plt.figure(figsize = (28,20))\n",
    "   plt.xticks([0.0,0.5,1.0,1.5,2.0],fontsize = 80)\n",
    "   plt.yticks(fontsize = 80)\n",
    "   for k in range(len(trot)):\n",
    "       c_1 = next(color_1)\n",
    "       beta = (float(dtau))*(float(trot[k]))\n",
    "       T = round(1/beta,2)\n",
    "       plt.errorbar(x_val[:,k],y_val[:,k],yerr = y_val_err[:,k],c=c_1,marker = 'o',markersize = 20, elinewidth = 3, capsize = 5,label = r\"T = %s\"%str(T))\n",
    "   plt.grid(True,which='both')\n",
    "   plt.legend(loc = 'best',ncol = int(len(trot)/2),fontsize = 50)\n",
    "   plt.axhline(y=0,color='black',linestyle = 'dashed',linewidth = 2)   \n",
    "   plt.tight_layout()\n",
    "   plt.savefig(plot_name)\n",
    "   plt.close()\n",
    "\n",
    "def plot_func_multiple_U_doping(N,u_val,mu,dtau,trot,plot_title,plot_x_label,plot_y_label,x_val,y_val,y_val_err,plot_name):\n",
    "\n",
    "   color_1 = iter(['blue','darkgreen','olive','darkgoldenrod','orange','red'])\n",
    "   plt.figure(figsize = (28,20))\n",
    "   #plt.title(plot_title,fontsize = 60)\n",
    "   plt.xticks(fontsize = 80)\n",
    "   plt.yticks(fontsize = 80)\n",
    "   #plt.xscale('log')\n",
    "   #plt.yscale('log') \n",
    "   #plt.ylabel(plot_y_label,fontsize = 60)\n",
    "   #plt.xlabel(plot_x_label,fontsize = 60)\n",
    "   #plt.errorbar(x_val_met,y_val_met,yerr = y_val_err_met,c='blue',marker = 'o',markersize = 20, elinewidth = 3, capsize = 5,label = r\"U = 1.0\")\n",
    "   for i in range(len(u_val)):\n",
    "       c_1 = next(color_1)\n",
    "       plt.errorbar(x_val[i,:],y_val[i,:],yerr = y_val_err[i,:],c=c_1,marker = 'o',markersize = 20, elinewidth = 3, capsize = 5,label = r\"U = %s\"%str(u_val[i]))\n",
    "   #plt.errorbar(x_val_ins,y_val_ins,yerr = y_val_err_ins,c='red',marker = 'o',markersize = 20, elinewidth = 3, capsize = 5,label = r\"U = 8.0\")\n",
    "   plt.axhline(y=0,color='black',linestyle = 'dashed',linewidth = 2) \n",
    "   plt.grid(True,which='both')\n",
    "   plt.legend(loc = 'best',ncol=1,fontsize = 50)\n",
    "   plt.tight_layout()\n",
    "   plt.savefig(plot_name)\n",
    "   plt.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2123e23d-f761-441c-b983-d4496c13fb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equal_time_moment_moment_correlation_function_half_filling(Text_dir_main_corr_hf,Text_dir_main_eqm,Graph_dir_hf,N,u,mu,dtau,L):\n",
    "\n",
    "   r_grid, r_rel_grid_size = r_point_upper_half_grid(N)\n",
    "   r_rel_x = r_grid[:,0]\n",
    "   r_rel_y = r_grid[:,1]\n",
    "\n",
    "   r_2 = np.add(np.power(r_rel_x,2),np.power(r_rel_y,2))\n",
    "   r_2_unq = np.sort(np.unique(r_2))\n",
    "\n",
    "   M2_M2_corr_hf = np.zeros((len(u),len(L),len(r_2_unq)))\n",
    "   M2_M2_corr_hf_std = np.zeros((len(u),len(L),len(r_2_unq)))\n",
    "   \n",
    "   M2_M2_conn_corr_hf = np.zeros((len(u),len(L),len(r_2_unq)))\n",
    "   M2_M2_conn_corr_hf_std = np.zeros((len(u),len(L),len(r_2_unq)))\n",
    "   \n",
    "   Nrm_M2_M2_conn_corr_hf = np.zeros((len(u),len(L),len(r_2_unq)))\n",
    "   Nrm_M2_M2_conn_corr_hf_std = np.zeros((len(u),len(L),len(r_2_unq)))\n",
    "\n",
    "   Nden = np.zeros((len(u),len(L)))\n",
    "   Nden_std = np.zeros((len(u),len(L)))\n",
    "   Ndbn = np.zeros((len(u),len(L)))\n",
    "   Ndbn_std = np.zeros((len(u),len(L)))\n",
    "    \n",
    "   Nhln = np.zeros((len(u),len(L)))\n",
    "   Nhln_std = np.zeros((len(u),len(L)))\n",
    "    \n",
    "   M2 = np.zeros((len(u),len(L)))\n",
    "   M2_std = np.zeros((len(u),len(L)))\n",
    "\n",
    "    \n",
    "   U_val = np.zeros(len(u))\n",
    "   for i in range(len(u)):\n",
    "       U_val[i] = float(u[i])\n",
    "       \n",
    "   T_val = np.zeros(len(L))    \n",
    "   for k in range(len(L)):\n",
    "       T_val[k] = 1/(float(dtau)*float(L[k]))\n",
    "       \n",
    "   for i in range(len(u)):\n",
    "       for k in range(len(L)):\n",
    "                       \n",
    "           Text_dir_eqm = \"%s/Text_files_N_%s_U_%s_dtau_%s/Mu_%s/dtau_%s_L_%s/Thermodynamic_measurements\"%(Text_dir_main_eqm,N,u[i],dtau,mu,dtau,L[k])\n",
    "\n",
    "           filename_eqm_avg = '%s/Thermodynamic_measurements_normal_averaged_dictionary_N_%s_U_%s_mu_%s_dtau_%s_L_%s.pkl' %(Text_dir_eqm,N,u[i],mu,dtau,L[k])\n",
    "           with open(filename_eqm_avg, 'rb') as infile:\n",
    "                sys_measure_avg = pickle.load(infile)\n",
    "\n",
    "           filename_eqm_std = '%s/Thermodynamic_measurements_normal_standard_deviation_dictionary_N_%s_U_%s_mu_%s_dtau_%s_L_%s.pkl' %(Text_dir_eqm,N,u[i],mu,dtau,L[k])\n",
    "           with open(filename_eqm_std, 'rb') as infile:\n",
    "                sys_measure_std = pickle.load(infile)\n",
    "\n",
    "           Nden[i][k] = sys_measure_avg['Density averaged']\n",
    "           Nden_std[i][k] = sys_measure_std['Density standard deviation']\n",
    "           Ndbn[i,k] = sys_measure_avg['Doublon number averaged']\n",
    "           Ndbn_std[i,k] = sys_measure_std['Doublon number standard deviation']\n",
    "           \n",
    "           M2[i][k] = Nden[i][k]-2*Ndbn[i][k]\n",
    "           M2_std[i][k] = np.sqrt(4*Ndbn_std[i][k]*Ndbn_std[i][k]+Nden_std[i][k]*Nden_std[i][k])\n",
    "           \n",
    "           Text_dir_m2_m2_corr_hf = '%s/Text_files_N_%s_U_%s_dtau_%s/Mu_%s/dtau_%s_L_%s/Moment_moment_correlation_functions'%(Text_dir_main_corr_hf,N,u[i],dtau,mu,dtau,L[k])\n",
    "           Text_dir_m2_m2_conn_corr_hf = '%s/Text_files_N_%s_U_%s_dtau_%s/Mu_%s/dtau_%s_L_%s/Moment_moment_connected_correlation_functions'%(Text_dir_main_corr_hf,N,u[i],dtau,mu,dtau,L[k])\n",
    "\n",
    "           filename_m2_m2_corr = '%s/Equal_time_Moment_Moment_correlation_real_space_neighbor_averaged_normal_avg_N_%s_U_%s_mu_%s_dtau_%s_L_%s.dat'%(Text_dir_m2_m2_corr_hf,N,u[i],mu,dtau,L[k])\n",
    "           M2_M2_corr_hf[i,k,:],M2_M2_corr_hf_std[i,k,:] = np.loadtxt(filename_m2_m2_corr,unpack = 'True', usecols = [1,2])\n",
    "\n",
    "           filename_m2_m2_conn_corr = '%s/Equal_time_Moment_Moment_connected_correlation_real_space_neighbor_averaged_normal_avg_N_%s_U_%s_mu_%s_dtau_%s_L_%s.dat'%(Text_dir_m2_m2_conn_corr_hf,N,u[i],mu,dtau,L[k])\n",
    "           M2_M2_conn_corr_hf[i,k,:],M2_M2_conn_corr_hf_std[i,k,:] = np.loadtxt(filename_m2_m2_conn_corr,unpack = 'True', usecols = [1,2])\n",
    "\n",
    "\n",
    "           for r in range(len(r_2_unq)):\n",
    "               \n",
    "               Nrm_M2_M2_conn_corr_hf[i,k,r] = (1/(M2[i][k]*M2[i][k]))*(M2_M2_conn_corr_hf[i,k,r])\n",
    "               Nrm_M2_M2_conn_corr_hf_std[i,k,r] = Nrm_M2_M2_conn_corr_hf[i,k,r]*(M2_M2_conn_corr_hf_std[i,k,r]/M2_M2_conn_corr_hf[i,k,r]+2*M2_std[i][k]/M2[i][k])\n",
    "               \n",
    " \n",
    "   M2_M2_corr_hf_n0 = np.zeros((len(u),len(L)))\n",
    "   M2_M2_corr_hf_n1 = np.zeros((len(u),len(L)))\n",
    "   M2_M2_corr_hf_n2 = np.zeros((len(u),len(L)))\n",
    "   M2_M2_corr_hf_n3 = np.zeros((len(u),len(L)))\n",
    "\n",
    "   M2_M2_corr_hf_n0_std = np.zeros((len(u),len(L)))\n",
    "   M2_M2_corr_hf_n1_std = np.zeros((len(u),len(L)))\n",
    "   M2_M2_corr_hf_n2_std = np.zeros((len(u),len(L)))\n",
    "   M2_M2_corr_hf_n3_std = np.zeros((len(u),len(L)))\n",
    "\n",
    "   M2_M2_conn_corr_hf_n0 = np.zeros((len(u),len(L)))\n",
    "   M2_M2_conn_corr_hf_n0_anl = np.zeros((len(u),len(L)))\n",
    "   M2_M2_conn_corr_hf_n1 = np.zeros((len(u),len(L)))\n",
    "   M2_M2_conn_corr_hf_n2 = np.zeros((len(u),len(L)))\n",
    "   M2_M2_conn_corr_hf_n3 = np.zeros((len(u),len(L)))\n",
    "    \n",
    "   M2_M2_conn_corr_hf_n0_std = np.zeros((len(u),len(L)))\n",
    "\n",
    "   M2_M2_conn_corr_hf_n0_anl_std = np.zeros((len(u),len(L)))\n",
    "   M2_M2_conn_corr_hf_n1_std = np.zeros((len(u),len(L)))\n",
    "   M2_M2_conn_corr_hf_n2_std = np.zeros((len(u),len(L)))\n",
    "   M2_M2_conn_corr_hf_n3_std = np.zeros((len(u),len(L)))\n",
    "\n",
    "   Nrm_M2_M2_conn_corr_hf_n0 = np.zeros((len(u),len(L)))\n",
    "   Nrm_M2_M2_conn_corr_hf_n1 = np.zeros((len(u),len(L)))\n",
    "   Nrm_M2_M2_conn_corr_hf_n2 = np.zeros((len(u),len(L)))\n",
    "   Nrm_M2_M2_conn_corr_hf_n3 = np.zeros((len(u),len(L)))\n",
    "    \n",
    "   Nrm_M2_M2_conn_corr_hf_n0_std = np.zeros((len(u),len(L)))\n",
    "   Nrm_M2_M2_conn_corr_hf_n1_std = np.zeros((len(u),len(L)))\n",
    "   Nrm_M2_M2_conn_corr_hf_n2_std = np.zeros((len(u),len(L)))\n",
    "   Nrm_M2_M2_conn_corr_hf_n3_std = np.zeros((len(u),len(L)))\n",
    "\n",
    "\n",
    "   for i in range(len(u)):\n",
    "       for k in range(len(L)):\n",
    "\n",
    "           M2_M2_corr_hf_n0[i][k] = M2_M2_corr_hf[i][k][0]\n",
    "           M2_M2_corr_hf_n1[i][k] = M2_M2_corr_hf[i][k][1]\n",
    "           M2_M2_corr_hf_n2[i][k] = M2_M2_corr_hf[i][k][2]\n",
    "           M2_M2_corr_hf_n3[i][k] = M2_M2_corr_hf[i][k][3]\n",
    "\n",
    "           M2_M2_corr_hf_n0_std[i][k] = M2_M2_corr_hf_std[i][k][0]\n",
    "           M2_M2_corr_hf_n1_std[i][k] = M2_M2_corr_hf_std[i][k][1]\n",
    "           M2_M2_corr_hf_n2_std[i][k] = M2_M2_corr_hf_std[i][k][2]\n",
    "           M2_M2_corr_hf_n3_std[i][k] = M2_M2_corr_hf_std[i][k][3]\n",
    "\n",
    "           M2_M2_conn_corr_hf_n0[i][k] = M2_M2_conn_corr_hf[i][k][0]\n",
    "\n",
    "           M2_M2_conn_corr_hf_n0_anl[i][k] = M2[i][k]*(1-M2[i][k])\n",
    "           M2_M2_conn_corr_hf_n1[i][k] = M2_M2_conn_corr_hf[i][k][1]\n",
    "           M2_M2_conn_corr_hf_n2[i][k] = M2_M2_conn_corr_hf[i][k][2]\n",
    "           M2_M2_conn_corr_hf_n3[i][k] = M2_M2_conn_corr_hf[i][k][3]\n",
    "           \n",
    "           M2_M2_conn_corr_hf_n0_std[i][k] = M2_M2_conn_corr_hf_std[i][k][0]\n",
    "           M2_M2_conn_corr_hf_n0_anl_std[i][k] = np.sqrt(M2_std[i][k]*M2_std[i][k]+4*M2_std[i][k]*M2_std[i][k]*M2[i][k]*M2[i][k])\n",
    "           M2_M2_conn_corr_hf_n1_std[i][k] = M2_M2_conn_corr_hf_std[i][k][1]\n",
    "           M2_M2_conn_corr_hf_n2_std[i][k] = M2_M2_conn_corr_hf_std[i][k][2]\n",
    "           M2_M2_conn_corr_hf_n3_std[i][k] = M2_M2_conn_corr_hf_std[i][k][3]\n",
    "\n",
    "           Nrm_M2_M2_conn_corr_hf_n0[i][k] = Nrm_M2_M2_conn_corr_hf[i][k][0]\n",
    "           Nrm_M2_M2_conn_corr_hf_n1[i][k] = Nrm_M2_M2_conn_corr_hf[i][k][1]\n",
    "           Nrm_M2_M2_conn_corr_hf_n2[i][k] = Nrm_M2_M2_conn_corr_hf[i][k][2]\n",
    "           Nrm_M2_M2_conn_corr_hf_n3[i][k] = Nrm_M2_M2_conn_corr_hf[i][k][3]\n",
    "           \n",
    "           Nrm_M2_M2_conn_corr_hf_n0_std[i][k] = Nrm_M2_M2_conn_corr_hf_std[i][k][0]\n",
    "           Nrm_M2_M2_conn_corr_hf_n1_std[i][k] = Nrm_M2_M2_conn_corr_hf_std[i][k][1]\n",
    "           Nrm_M2_M2_conn_corr_hf_n2_std[i][k] = Nrm_M2_M2_conn_corr_hf_std[i][k][2]\n",
    "           Nrm_M2_M2_conn_corr_hf_n3_std[i][k] = Nrm_M2_M2_conn_corr_hf_std[i][k][3]\n",
    "           \n",
    "           \n",
    "   Pl_title_n0 = r\"$\\langle h_i d_j \\rangle_{C}$ |i-j|=0.0, $N=%sx%s, n = 1$\"%(N,N)\n",
    "   Pl_title_n1 = r\"$\\langle h_i d_j \\rangle_{C}$ |i-j|=1.0, $N=%sx%s, n = 1$\"%(N,N)\n",
    "   Pl_title_n2 = r\"$\\langle h_i d_j \\rangle_{C}$ |i-j|=1.414, $N=%sx%s, n = 1$\"%(N,N)\n",
    "   Pl_title_n3 = r\"$\\langle h_i d_j \\rangle_{C}$ |i-j|=2.0, $N=%sx%s, n = 1$\"%(N,N)\n",
    "\n",
    "   Pl_y_lab = r\"$\\langle h_i d_j \\rangle_{C}$\"\n",
    "   Pl_x_lab = r\"$U$\"\n",
    "\n",
    "\n",
    "   #=========================================================Comparing_different_T=============================== \n",
    "   Pl_name_n1 = \"%s/T_comp_Moment_moment_correlation_1st_nearest_neighbor_averaged_normal_averaged_half_filling_N_%s_dtau_%s.png\"%(Graph_dir_hf,N,dtau)\n",
    "   Pl_name_conn_n1 = \"%s/T_comp_Moment_moment_correlation_connected_1st_nearest_neighbor_averaged_normal_averaged_half_filling_N_%s_dtau_%s.png\"%(Graph_dir_hf,N,dtau)\n",
    "   Pl_name_nrm_conn_n1 = \"%s/T_comp_Normalized_Moment_moment_correlation_connected_1st_nearest_neighbor_averaged_normal_averaged_half_filling_N_%s_dtau_%s.png\"%(Graph_dir_hf,N,dtau)\n",
    "   Pl_name_conn_n0 = \"%s/T_comp_Moment_moment_correlation_connected_onsite_normal_averaged_half_filling_N_%s_dtau_%s.png\"%(Graph_dir_hf,N,dtau)\n",
    "   Pl_name_conn_n0_anl = \"%s/T_comp_analytical_Moment_moment_correlation_connected_onsite_half_filling_N_%s_dtau_%s.png\"%(Graph_dir_hf,N,dtau)\n",
    "        \n",
    "   Pl_name_m2 = \"%s/T_comp_Local_moment_normal_averaged_half_filling_N_%s_dtau_%s.png\"%(Graph_dir_hf,N,dtau)\n",
    "  \n",
    "   plot_func_multiple_beta_hf(N,u,mu,dtau,L,Pl_title_n1,Pl_x_lab,Pl_y_lab,U_val,M2_M2_corr_hf_n1,M2_M2_corr_hf_n1_std,Pl_name_n1)\n",
    "   plot_func_multiple_beta_hf(N,u,mu,dtau,L,Pl_title_n2,Pl_x_lab,Pl_y_lab,U_val,M2_M2_conn_corr_hf_n1,M2_M2_conn_corr_hf_n1_std,Pl_name_conn_n1)\n",
    "   plot_func_multiple_beta_hf(N,u,mu,dtau,L,Pl_title_n3,Pl_x_lab,Pl_y_lab,U_val,Nrm_M2_M2_conn_corr_hf_n1,Nrm_M2_M2_conn_corr_hf_n1_std,Pl_name_nrm_conn_n1)\n",
    "   plot_func_multiple_beta_hf(N,u,mu,dtau,L,Pl_title_n3,Pl_x_lab,Pl_y_lab,U_val,M2,M2_std,Pl_name_m2)\n",
    "   plot_func_multiple_beta_hf(N,u,mu,dtau,L,Pl_title_n2,Pl_x_lab,Pl_y_lab,U_val,M2_M2_conn_corr_hf_n0,M2_M2_conn_corr_hf_n0_std,Pl_name_conn_n0)\n",
    "   plot_func_multiple_beta_hf(N,u,mu,dtau,L,Pl_title_n2,Pl_x_lab,Pl_y_lab,U_val,M2_M2_conn_corr_hf_n0_anl,M2_M2_conn_corr_hf_n0_anl_std,Pl_name_conn_n0_anl)\n",
    "    \n",
    "   Pl_name_n1_u = \"%s/U_comp_Moment_moment_correlation_1st_nearest_neighbor_averaged_normal_averaged_half_filling_N_%s_dtau_%s.png\"%(Graph_dir_hf,N,dtau)\n",
    "   Pl_name_conn_n1_u = \"%s/U_comp_Moment_moment_correlation_connected_1st_nearest_neighbor_averaged_normal_averaged_half_filling_N_%s_dtau_%s.png\"%(Graph_dir_hf,N,dtau)\n",
    "   Pl_name_nrm_conn_n1_u = \"%s/U_comp_Normalized_Moment_moment_correlation_connected_1st_nearest_neighbor_averaged_normal_averaged_half_filling_N_%s_dtau_%s.png\"%(Graph_dir_hf,N,dtau)\n",
    "   \n",
    "   Pl_name_m2_u = \"%s/U_comp_Local_moment_normal_averaged_half_filling_N_%s_dtau_%s.png\"%(Graph_dir_hf,N,dtau)\n",
    "  \n",
    "   plot_func_multiple_U_hf(N,u,mu,dtau,L,Pl_title_n1,Pl_x_lab,Pl_y_lab,T_val,M2_M2_corr_hf_n1,M2_M2_corr_hf_n1_std,Pl_name_n1_u)\n",
    "   plot_func_multiple_U_hf(N,u,mu,dtau,L,Pl_title_n2,Pl_x_lab,Pl_y_lab,T_val,M2_M2_conn_corr_hf_n1,M2_M2_conn_corr_hf_n1_std,Pl_name_conn_n1_u)\n",
    "   plot_func_multiple_U_hf(N,u,mu,dtau,L,Pl_title_n3,Pl_x_lab,Pl_y_lab,T_val,Nrm_M2_M2_conn_corr_hf_n1,Nrm_M2_M2_conn_corr_hf_n1_std,Pl_name_nrm_conn_n1_u)\n",
    "   plot_func_multiple_U_hf(N,u,mu,dtau,L,Pl_title_n3,Pl_x_lab,Pl_y_lab,T_val,M2,M2_std,Pl_name_m2_u)\n",
    "    \n",
    "   #=================================Fitting data==========================================\n",
    "\n",
    "   #n_pts = 801\n",
    "   #U_fit = np.linspace(1.00,10.00,num=n_pts)\n",
    "   #Cmm1_fit = np.zeros((len(U_fit),len(L)))\n",
    "   #Nrm_Cmm1_fit = np.zeros((len(U_fit),len(L)))\n",
    "   \n",
    "   #U_max_fit = np.zeros(len(L))\n",
    "   #Nrm_U_max_fit = np.zeros(len(L))\n",
    "   #U_max_qmc = np.zeros(len(L))\n",
    "\n",
    "   #Graph_dir_fit = \"%s/Data_fit_polynomial\"%Graph_dir_hf\n",
    "   #if not os.path.exists(Graph_dir_fit):\n",
    "   #   os.makedirs(Graph_dir_fit)\n",
    "\n",
    "\n",
    "   #for k in range(len(L)):\n",
    "   #    T_val[k] = 1/(float(dtau)*float(L[k]))\n",
    "   #    Poly_fit = np.polynomial.polynomial.Polynomial(np.polynomial.polynomial.polyfit(U_val,M2_M2_conn_corr_hf_n1[:,k],10))\n",
    "   #    Cmm1_fit[:,k] = Poly_fit(U_fit)\n",
    "   #    Nrm_Poly_fit = np.polynomial.polynomial.Polynomial(np.polynomial.polynomial.polyfit(U_val,Nrm_M2_M2_conn_corr_hf_n1[:,k],10))\n",
    "   #    Nrm_Cmm1_fit[:,k] = Nrm_Poly_fit(U_fit)    \n",
    "       \n",
    "   #    plt.figure(figsize = (20,20))\n",
    "   #    plt.xticks(fontsize = 40)\n",
    "   #    plt.yticks(fontsize = 40)\n",
    "   #    plt.xlabel(\"U\",fontsize = 40)\n",
    "   #    plt.ylabel(r\"$C_{mm}(1)$\",fontsize = 40)\n",
    "   #    plt.errorbar(U_val,Nrm_M2_M2_conn_corr_hf_n1[:,k],yerr = Nrm_M2_M2_conn_corr_hf_n1_std[:,k],marker = 'o',markersize = 15,capsize =5, elinewidth = 3)\n",
    "   #    plt.plot(U_fit,Nrm_Cmm1_fit[:,k],linewidth = 3,label = \"Data_fit\")\n",
    "   #    plt.legend(loc = 'best',fontsize =40)\n",
    "   #    plt.savefig(\"%s/Data_fit_normalized_correlator_N_%s_dtau_%s_L_%s_normal_avg.png\"%(Graph_dir_fit,N,dtau,L[k]))\n",
    "\n",
    "   #    plt.figure(figsize = (20,20))\n",
    "   #    plt.xticks(fontsize = 40)\n",
    "   #    plt.yticks(fontsize = 40)\n",
    "   #    plt.xlabel(\"U\",fontsize = 40)\n",
    "   #    plt.ylabel(r\"$C_{mm}(1)$\",fontsize = 40)\n",
    "   #    plt.errorbar(U_val,M2_M2_conn_corr_hf_n1[:,k],yerr = M2_M2_conn_corr_hf_n1_std[:,k],marker = 'o',markersize = 15,capsize =5, elinewidth = 3)\n",
    "   #    plt.plot(U_fit,Cmm1_fit[:,k],linewidth = 3,label = \"Data_fit\")\n",
    "   #    plt.legend(loc = 'best',fontsize =40)\n",
    "   #    plt.savefig(\"%s/Data_fit_correlator_N_%s_dtau_%s_L_%s_normal_avg.png\"%(Graph_dir_fit,N,dtau,L[k]))\n",
    "\n",
    "       \n",
    "   #    U_max_fit[k] = U_fit[np.argmax(Cmm1_fit[:,k])]\n",
    "   #    Nrm_U_max_fit[k] = U_fit[np.argmax(Nrm_Cmm1_fit[:,k])]\n",
    "   #    U_max_qmc[k] = U_val[np.argmax(Nrm_M2_M2_conn_corr_hf_n1[:,k])]\n",
    "\n",
    "\n",
    "   #U_val_LDOS = np.asarray([3.20,3.30,3.40,3.50,3.60,3.70,3.80,3.90,4.00,4.10,4.20,4.300,4.40,4.50,4.700,4.800,4.900,5.00]) #,5.100,5.200,5.500,6.000,6.500])\n",
    "   #T_c_LDOS =   np.asarray([0.30,0.30,0.30,0.30,0.30,0.30,0.30,0.33,0.33,0.33,0.33,0.345,0.40,0.40,0.417,0.417,0.455,0.50]) #,0.556,0.556,0.667,0.833,1.000])\n",
    "\n",
    "   #print(T_val,\"T\")\n",
    "   #print(U_max_fit,\"U_fit\")\n",
    "   #print(U_max_qmc,\"U_qmc\")\n",
    "\n",
    "   #plt.figure(figsize = (25,20))\n",
    "   #plt.xticks(fontsize = 80)\n",
    "   #plt.yticks(fontsize = 80)\n",
    "   #plt.plot(T_val,U_max_fit,marker = \"o\",markersize = 25,label = \"Conn\")\n",
    "   #plt.plot(T_val,Nrm_U_max_fit,marker = \"o\",markersize = 25,label = \"Nrm\")    \n",
    "   #plt.plot(T_c_LDOS,U_val_LDOS,marker = \"^\",markersize = 25) \n",
    "   #plt.grid(True,which='both')\n",
    "   #plt.legend(loc = 'best',fontsize = 50) \n",
    "   #plt.savefig(\"%s/T_max_normalized_moment_correlations.png\"%Graph_dir_hf) \n",
    "   #coef = np.polyfit(T_val,U_max_fit,1)\n",
    "   #line_fit = np.poly1d(coef)\n",
    "   #T_x = np.arange(0,1.1,0.1)\n",
    "   #U_x = line_fit(T_x)\n",
    "   #T_w = np.array([0.2848484848484848,0.19878787878787876,0.1533333333333333,0.12424242424242421,0.09999999999999998])\n",
    "   #U_w = np.array([6.7899159663865545,6.369747899159664,6.30252100840336,6.100840336134454,6])\n",
    "   #print(U_x[0])\n",
    "   #plt.figure(figsize = (30,20))\n",
    "   #plt.xlabel(\"T\",fontsize = 80)\n",
    "   #plt.ylabel(r\"$U_{max}$\",fontsize = 80)\n",
    "   #plt.xticks([0.0,0.25,0.5,0.75,1.0],fontsize = 120)\n",
    "   #plt.yticks([U_x[0],5.75,6.00,6.25,6.50,6.75,7.00],fontsize = 120)\n",
    "   #plt.plot(T_val,U_max_fit,marker = 'o',markersize = 55,label = \"Data_fit,n = %s\"%str(n_pts))\n",
    "   #plt.plot(T_val,U_max_qmc,marker = 'o',markersize = 15,linewidth = 5,label = \"QMC\")\n",
    "   #plt.plot(T_x,U_x,'--k',linewidth = 10)\n",
    "   #plt.plot(T_w,U_w,marker = 's',markersize = 55,label = \"Widom line\")\n",
    "   #plt.legend(loc = 'best',fontsize = 60)\n",
    "   #plt.axhline(y=U_x[0],linestyle = '--',color = 'b')\n",
    "   #plt.grid('True')\n",
    "   #plt.xlim(0,1.01)\n",
    "   #plt.text(4, 1, 'y=%s'%(U_x[0]))\n",
    "   #plt.tight_layout()\n",
    "   #plt.savefig(\"%s/U_max_Cmm1_N_%s_dtau_%s_n_points_%s.png\"%(Graph_dir_hf,N,dtau,str(n_pts)))\n",
    "\n",
    "\n",
    "   #color_1 = iter(cm.gnuplot(np.linspace(0, 1, len(L)+1)))\n",
    "   #plt.figure(figsize = (25,20))\n",
    "   #plt.xticks([2.0,4.0,6.0,8.0,10.0],fontsize = 80)\n",
    "   #plt.yticks(fontsize = 80)\n",
    "   #plt.xlabel(\"U\",fontsize = 40)\n",
    "   #plt.ylabel(r\"$C_{mm}(1)$\",fontsize = 40)\n",
    "   #for k in range(len(L)-1,-1,-1):\n",
    "   #    c_1 = next(color_1)\n",
    "   #    plt.errorbar(U_val[Uc1_ind:Uc2_ind+1],Mmt_Mmt_corr_hf_n1[Uc1_ind:Uc2_ind+1,k],yerr = Mmt_Mmt_corr_hf_n1_std[Uc1_ind:Uc2_ind+1,k], ls='none',c=c_1,marker = 'o',markersize = 25,capsize =5, elinewidth = 3)\n",
    "   #    plt.plot(U_fit,Cmm1_fit[:,k],c=c_1,linestyle = '--',linewidth = 3,label = \"T=%s\"%str(round(T_val[k],2)))\n",
    "   #plt.legend(loc = 'upper left',fontsize =50)\n",
    "   #plt.axvspan(3.5,4.2,color='red',alpha=0.5)\n",
    "  # plt.axvspan(4.5,6.65,color='blue',alpha=0.3)\n",
    "  # plt.grid('True',which='both')\n",
    "  # plt.savefig(\"%s/Data_fit_N_%s_dtau_%s_fitting_compare_normal_avg.png\"%(Graph_dir_hf,N,dtau))\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "812207e9-130a-4012-84a4-3ac3048cbd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equal_time_moment_moment_correlation_function_doping(Text_dir_main_corr,Text_dir_main_eqm,Graph_dir,N,u,Mu,dtau,L):\n",
    "   \n",
    "   Adj_list = adj_mat_calc(N)\n",
    "    \n",
    "   r_grid, r_rel_grid_size = r_point_upper_half_grid(N)\n",
    "   r_rel_x = r_grid[:,0]\n",
    "   r_rel_y = r_grid[:,1]\n",
    "\n",
    "   r_2 = np.add(np.power(r_rel_x,2),np.power(r_rel_y,2))\n",
    "   r_2_unq = np.sort(np.unique(r_2))\n",
    "\n",
    "   M2_M2_corr = np.zeros((len(u),len(Mu),len(L),len(r_2_unq)))\n",
    "   M2_M2_corr_std = np.zeros((len(u),len(Mu),len(L),len(r_2_unq)))\n",
    "   \n",
    "   M2_M2_conn_corr = np.zeros((len(u),len(Mu),len(L),len(r_2_unq)))\n",
    "   M2_M2_conn_corr_std = np.zeros((len(u),len(Mu),len(L),len(r_2_unq)))\n",
    "   \n",
    "   Den_Dbn_conn_corr = np.zeros((len(u),len(Mu),len(L),len(r_2_unq)))\n",
    "   Den_Dbn_conn_corr_std = np.zeros((len(u),len(Mu),len(L),len(r_2_unq)))\n",
    "    \n",
    "   Nrm_M2_M2_conn_corr = np.zeros((len(u),len(Mu),len(L),len(r_2_unq)))\n",
    "   Nrm_M2_M2_conn_corr_std = np.zeros((len(u),len(Mu),len(L),len(r_2_unq)))\n",
    "\n",
    "   Nden = np.zeros((len(u),len(Mu),len(L)))\n",
    "   Nden_std = np.zeros((len(u),len(Mu),len(L)))\n",
    "   Ndbn = np.zeros((len(u),len(Mu),len(L)))\n",
    "   Ndbn_std = np.zeros((len(u),len(Mu),len(L)))\n",
    "    \n",
    "   Nhln = np.zeros((len(u),len(Mu),len(L)))\n",
    "   Nhln_std = np.zeros((len(u),len(Mu),len(L)))\n",
    "    \n",
    "   M2 = np.zeros((len(u),len(Mu),len(L)))\n",
    "   M2_std = np.zeros((len(u),len(Mu),len(L)))\n",
    "\n",
    "   Mu_val =  np.zeros((len(u),len(Mu),len(L)))\n",
    "   U_val = np.zeros(len(u))\n",
    "   for i in range(len(u)):\n",
    "       U_val[i] = float(u[i])\n",
    "       \n",
    "   T_val = np.zeros(len(L))   \n",
    "    \n",
    "   for i in range(len(u)):\n",
    "       for j in range(len(Mu)):\n",
    "           for k in range(len(L)):\n",
    "               Mu_val[i][j][k] = float(Mu[j])        \n",
    "               Text_dir_eqm = \"%s/Text_files_N_%s_U_%s_dtau_%s/Mu_%s/dtau_%s_L_%s/Thermodynamic_measurements\"%(Text_dir_main_eqm,N,u[i],dtau,Mu[j],dtau,L[k])\n",
    "\n",
    "               filename_eqm_avg = '%s/Thermodynamic_measurements_normal_averaged_dictionary_N_%s_U_%s_mu_%s_dtau_%s_L_%s.pkl' %(Text_dir_eqm,N,u[i],Mu[j],dtau,L[k])\n",
    "               with open(filename_eqm_avg, 'rb') as infile:\n",
    "                    sys_measure_avg = pickle.load(infile)\n",
    "\n",
    "               filename_eqm_std = '%s/Thermodynamic_measurements_normal_standard_deviation_dictionary_N_%s_U_%s_mu_%s_dtau_%s_L_%s.pkl' %(Text_dir_eqm,N,u[i],Mu[j],dtau,L[k])\n",
    "               with open(filename_eqm_std, 'rb') as infile:\n",
    "                    sys_measure_std = pickle.load(infile)\n",
    "\n",
    "               Nden[i][j][k] = sys_measure_avg['Density averaged']\n",
    "               Nden_std[i][j][k] = sys_measure_std['Density standard deviation']\n",
    "               Ndbn[i][j][k] = sys_measure_avg['Doublon number averaged']\n",
    "               Ndbn_std[i][j][k] = sys_measure_std['Doublon number standard deviation']\n",
    "           \n",
    "               M2[i][j][k] = np.abs(Nden[i][j][k]-2*Ndbn[i][j][k])\n",
    "               M2_std[i][j][k] = np.sqrt(4*Ndbn_std[i][j][k]*Ndbn_std[i][j][k]+Nden_std[i][j][k]*Nden_std[i][j][k])\n",
    "           \n",
    "               #Text_dir_m2_m2_corr = '%s/Text_files_N_%s_U_%s_dtau_%s/Mu_%s/dtau_%s_L_%s/Moment_moment_correlation_functions'%(Text_dir_main_corr,N,u[i],dtau,Mu[j],dtau,L[k])\n",
    "               Text_dir_m2_m2_conn_corr = '%s/Text_files_N_%s_U_%s_dtau_%s/Mu_%s/dtau_%s_L_%s/Moment_moment_connected_correlation_functions'%(Text_dir_main_corr,N,u[i],dtau,Mu[j],dtau,L[k])\n",
    "\n",
    "               #Text_dir_den_dbn_conn_corr = '%s/Text_files_N_%s_U_%s_dtau_%s/Mu_%s/dtau_%s_L_%s/Density_doublon_connected_correlation_functions'%(Text_dir_main_corr,N,u[i],dtau,Mu[j],dtau,L[k])\n",
    "\n",
    "               #filename_den_dbn_conn_corr = '%s/Equal_time_Density_Doublon_connected_correlation_real_space_neighbor_averaged_normal_avg_N_%s_U_%s_mu_%s_dtau_%s_L_%s.dat'%(Text_dir_den_dbn_conn_corr,N,u[i],Mu[j],dtau,L[k])\n",
    "               #Den_Dbn_conn_corr[i,j,k,:],Den_Dbn_conn_corr_std[i,j,k,:] = np.loadtxt(filename_den_dbn_conn_corr,unpack = 'True', usecols = [1,2])\n",
    "\n",
    "           \n",
    "               #filename_m2_m2_corr = '%s/Equal_time_Moment_Moment_correlation_real_space_neighbor_averaged_normal_avg_N_%s_U_%s_mu_%s_dtau_%s_L_%s.dat'%(Text_dir_m2_m2_corr,N,u[i],Mu[j],dtau,L[k])\n",
    "               #M2_M2_corr[i,j,k,:],M2_M2_corr_std[i,j,k,:] = np.loadtxt(filename_m2_m2_corr,unpack = 'True', usecols = [1,2])\n",
    "\n",
    "               filename_m2_m2_conn_corr = '%s/Equal_time_Moment_Moment_connected_correlation_real_space_neighbor_averaged_normal_avg_N_%s_U_%s_mu_%s_dtau_%s_L_%s.dat'%(Text_dir_m2_m2_conn_corr,N,u[i],Mu[j],dtau,L[k])\n",
    "               M2_M2_conn_corr[i,j,k,:],M2_M2_conn_corr_std[i,j,k,:] = np.loadtxt(filename_m2_m2_conn_corr,unpack = 'True', usecols = [1,2])\n",
    "\n",
    "\n",
    "               for r in range(len(r_2_unq)):\n",
    "               \n",
    "                   Nrm_M2_M2_conn_corr[i,j,k,r] = (1/(M2[i][j][k]*M2[i][j][k]))*(M2_M2_conn_corr[i,j,k,r])\n",
    "                   Nrm_M2_M2_conn_corr_std[i,j,k,r] = np.abs(Nrm_M2_M2_conn_corr[i,j,k,r])*(M2_M2_conn_corr_std[i,j,k,r]/np.abs(M2_M2_conn_corr[i,j,k,r])+2*M2_std[i][j][k]/M2[i][j][k])\n",
    "               \n",
    "\n",
    "   Onsite_m2 = np.zeros((len(u),len(Mu),len(L)))\n",
    "   Onsite_m2_std = np.zeros((len(u),len(Mu),len(L))) \n",
    "   M2_M2_corr_n0 = np.zeros((len(u),len(Mu),len(L)))\n",
    "   M2_M2_corr_n1 = np.zeros((len(u),len(Mu),len(L)))\n",
    "   M2_M2_corr_n2 = np.zeros((len(u),len(Mu),len(L)))\n",
    "   M2_M2_corr_n3 = np.zeros((len(u),len(Mu),len(L)))\n",
    "\n",
    "   M2_M2_corr_n0_std = np.zeros((len(u),len(Mu),len(L)))\n",
    "   M2_M2_corr_n1_std = np.zeros((len(u),len(Mu),len(L)))\n",
    "   M2_M2_corr_n2_std = np.zeros((len(u),len(Mu),len(L)))\n",
    "   M2_M2_corr_n3_std = np.zeros((len(u),len(Mu),len(L)))\n",
    "\n",
    "   M2_M2_conn_corr_n0 = np.zeros((len(u),len(Mu),len(L)))\n",
    "   M2_M2_conn_corr_n1 = np.zeros((len(u),len(Mu),len(L)))\n",
    "   M2_M2_conn_corr_n2 = np.zeros((len(u),len(Mu),len(L)))\n",
    "   M2_M2_conn_corr_n3 = np.zeros((len(u),len(Mu),len(L)))\n",
    "   M2_M2_conn_corr_nl = np.zeros((len(u),len(Mu),len(L)))\n",
    "   M2_M2_conn_corr_tot = np.zeros((len(u),len(Mu),len(L)))\n",
    "    \n",
    "   M2_M2_conn_corr_n0_std = np.zeros((len(u),len(Mu),len(L)))\n",
    "   M2_M2_conn_corr_n1_std = np.zeros((len(u),len(Mu),len(L)))\n",
    "   M2_M2_conn_corr_n2_std = np.zeros((len(u),len(Mu),len(L)))\n",
    "   M2_M2_conn_corr_n3_std = np.zeros((len(u),len(Mu),len(L)))\n",
    "   M2_M2_conn_corr_nl_std = np.zeros((len(u),len(Mu),len(L)))\n",
    "   M2_M2_conn_corr_tot_std = np.zeros((len(u),len(Mu),len(L)))\n",
    "    \n",
    "   Nrm_M2_M2_conn_corr_n0 = np.zeros((len(u),len(Mu),len(L)))\n",
    "   Nrm_M2_M2_conn_corr_n1 = np.zeros((len(u),len(Mu),len(L)))\n",
    "   Nrm_M2_M2_conn_corr_n2 = np.zeros((len(u),len(Mu),len(L)))\n",
    "   Nrm_M2_M2_conn_corr_n3 = np.zeros((len(u),len(Mu),len(L)))\n",
    "    \n",
    "   Nrm_M2_M2_conn_corr_n0_std = np.zeros((len(u),len(Mu),len(L)))\n",
    "   Nrm_M2_M2_conn_corr_n1_std = np.zeros((len(u),len(Mu),len(L)))\n",
    "   Nrm_M2_M2_conn_corr_n2_std = np.zeros((len(u),len(Mu),len(L)))\n",
    "   Nrm_M2_M2_conn_corr_n3_std = np.zeros((len(u),len(Mu),len(L)))\n",
    "\n",
    "\n",
    "   for i in range(len(u)):\n",
    "       for j in range(len(Mu)):\n",
    "           for k in range(len(L)):\n",
    "\n",
    "               M2_M2_corr_n0[i][j][k] = M2_M2_corr[i][j][k][0]\n",
    "               M2_M2_corr_n1[i][j][k] = M2_M2_corr[i][j][k][1]\n",
    "               M2_M2_corr_n2[i][j][k] = M2_M2_corr[i][j][k][2]\n",
    "               M2_M2_corr_n3[i][j][k] = M2_M2_corr[i][j][k][3]\n",
    "\n",
    "               M2_M2_corr_n0_std[i][j][k] = M2_M2_corr_std[i][j][k][0]\n",
    "               M2_M2_corr_n1_std[i][j][k] = M2_M2_corr_std[i][j][k][1]\n",
    "               M2_M2_corr_n2_std[i][j][k] = M2_M2_corr_std[i][j][k][2]\n",
    "               M2_M2_corr_n3_std[i][j][k] = M2_M2_corr_std[i][j][k][3]\n",
    "\n",
    "               M2_M2_conn_corr_n0[i][j][k] = M2_M2_conn_corr[i][j][k][0]\n",
    "               M2_M2_conn_corr_n1[i][j][k] = M2_M2_conn_corr[i][j][k][1]\n",
    "               M2_M2_conn_corr_n2[i][j][k] = M2_M2_conn_corr[i][j][k][2]\n",
    "               M2_M2_conn_corr_n3[i][j][k] = M2_M2_conn_corr[i][j][k][3]\n",
    "               M2_M2_conn_corr_nl[i,j,k] = np.dot(M2_M2_conn_corr[i,j,k,1:],Adj_list[1:,1])\n",
    "               M2_M2_conn_corr_nl_std[i,j,k] = np.sqrt(np.dot(np.power(M2_M2_conn_corr_std[i,j,k,1:],2),Adj_list[1:,1])) \n",
    "\n",
    "               M2_M2_conn_corr_tot[i,j,k] = np.dot(M2_M2_conn_corr[i,j,k,:],Adj_list[:,1])\n",
    "               M2_M2_conn_corr_tot_std[i,j,k] = np.sqrt(np.dot(np.power(M2_M2_conn_corr_std[i,j,k,:],2),Adj_list[:,1])) \n",
    "               \n",
    "               M2_M2_conn_corr_n0_std[i][j][k] = M2_M2_conn_corr_std[i][j][k][0]\n",
    "               M2_M2_conn_corr_n1_std[i][j][k] = M2_M2_conn_corr_std[i][j][k][1]\n",
    "               M2_M2_conn_corr_n2_std[i][j][k] = M2_M2_conn_corr_std[i][j][k][2]\n",
    "               M2_M2_conn_corr_n3_std[i][j][k] = M2_M2_conn_corr_std[i][j][k][3]\n",
    "\n",
    "               Nrm_M2_M2_conn_corr_n0[i][j][k] = Nrm_M2_M2_conn_corr[i][j][k][0]\n",
    "               Nrm_M2_M2_conn_corr_n1[i][j][k] = Nrm_M2_M2_conn_corr[i][j][k][1]\n",
    "               Nrm_M2_M2_conn_corr_n2[i][j][k] = Nrm_M2_M2_conn_corr[i][j][k][2]\n",
    "               Nrm_M2_M2_conn_corr_n3[i][j][k] = Nrm_M2_M2_conn_corr[i][j][k][3]\n",
    "           \n",
    "               Nrm_M2_M2_conn_corr_n0_std[i][j][k] = Nrm_M2_M2_conn_corr_std[i][j][k][0]\n",
    "               Nrm_M2_M2_conn_corr_n1_std[i][j][k] = Nrm_M2_M2_conn_corr_std[i][j][k][1]\n",
    "               Nrm_M2_M2_conn_corr_n2_std[i][j][k] = Nrm_M2_M2_conn_corr_std[i][j][k][2]\n",
    "               Nrm_M2_M2_conn_corr_n3_std[i][j][k] = Nrm_M2_M2_conn_corr_std[i][j][k][3]\n",
    "\n",
    "               #Onsite_m2[i][j][k] = Nden[i][j][k]*(1-Nden[i][j][k])+4*Ndbn[i][j][k]*(1-Ndbn[i][j][k])-2*Den_Dbn_conn_corr[i,j,k,0]\n",
    "               #Onsite_m2_std[i][j][k] = Nden_std[i][j][k]\n",
    "           \n",
    "   Pl_title_n0 = r\"$\\langle h_i d_j \\rangle_{C}$ |i-j|=0.0, $N=%sx%s, n = 1$\"%(N,N)\n",
    "   Pl_title_n1 = r\"$\\langle h_i d_j \\rangle_{C}$ |i-j|=1.0, $N=%sx%s, n = 1$\"%(N,N)\n",
    "   Pl_title_n2 = r\"$\\langle h_i d_j \\rangle_{C}$ |i-j|=1.414, $N=%sx%s, n = 1$\"%(N,N)\n",
    "   Pl_title_n3 = r\"$\\langle h_i d_j \\rangle_{C}$ |i-j|=2.0, $N=%sx%s, n = 1$\"%(N,N)\n",
    "\n",
    "   Pl_title_n0 = r\"$\\langle h_i d_j \\rangle_{C}$ |i-j|=0.0, $N=%sx%s, n = 1$\"%(N,N)\n",
    "   Pl_title_n1 = r\"$\\langle h_i d_j \\rangle_{C}$ |i-j|=1.0, $N=%sx%s, n = 1$\"%(N,N)\n",
    "   Pl_title_n2 = r\"$\\langle h_i d_j \\rangle_{C}$ |i-j|=1.414, $N=%sx%s, n = 1$\"%(N,N)\n",
    "   Pl_title_n3 = r\"$\\langle h_i d_j \\rangle_{C}$ |i-j|=2.0, $N=%sx%s, n = 1$\"%(N,N)\n",
    "\n",
    "   Pl_y_lab = r\"$\\langle h_i d_j \\rangle_{C}$\"\n",
    "   Pl_x_lab = r\"$U$\"\n",
    "\n",
    "   Graph_dir_U_comp = \"%s/Graph_dir_U_comp\"%Graph_dir\n",
    "   if not os.path.exists(Graph_dir_U_comp):\n",
    "       os.makedirs(Graph_dir_U_comp)\n",
    "\n",
    "   Graph_dir_T_comp = \"%s/Graph_dir_T_comp\"%Graph_dir\n",
    "   if not os.path.exists(Graph_dir_T_comp):\n",
    "       os.makedirs(Graph_dir_T_comp)\n",
    "\n",
    "    \n",
    "   for i in range(len(u)):\n",
    "       \n",
    "       Pl_name_n0 = \"%s/Moment_moment_correlation_onsite_normal_averaged_N_%s_U_%s_dtau_%s.png\"%(Graph_dir_T_comp,N,u[i],dtau)\n",
    "       Pl_name_conn_n0 = \"%s/Moment_moment_correlation_connected_onsite_normal_averaged_N_%s_U_%s_dtau_%s.png\"%(Graph_dir_T_comp,N,u[i],dtau)\n",
    "       Pl_name_nrm_conn_n0 = \"%s/Normalized_Moment_moment_correlation_connected_onsite_normal_averaged_N_%s_U_%s_dtau_%s.png\"%(Graph_dir_T_comp,N,u[i],dtau)\n",
    "\n",
    "       Pl_name_n1 = \"%s/Moment_moment_correlation_1st_nearest_neighbor_averaged_normal_averaged_N_%s_U_%s_dtau_%s.png\"%(Graph_dir_T_comp,N,u[i],dtau)\n",
    "       Pl_name_conn_n1 = \"%s/Moment_moment_correlation_connected_1st_nearest_neighbor_averaged_normal_averaged_N_%s_U_%s_dtau_%s.png\"%(Graph_dir_T_comp,N,u[i],dtau)\n",
    "       Pl_name_nrm_conn_n1 = \"%s/Normalized_Moment_moment_correlation_connected_1st_nearest_neighbor_averaged_normal_averaged_N_%s_U_%s_dtau_%s.png\"%(Graph_dir_T_comp,N,u[i],dtau)\n",
    "\n",
    "       #Pl_name_hl_db = \"%s/Holon_doublon_product_normal_averaged_N_%s_dtau_%s_L_%s.png\"%(Graph_dir,N,dtau,L[k])\n",
    "       \n",
    "       plot_func_multiple_beta_doping(N,u[i],Mu,dtau,L,Pl_title_n1,Pl_x_lab,Pl_y_lab,Nden[i,:,:],M2_M2_corr_n0[i,:,:],M2_M2_corr_n1_std[i,:,:],Pl_name_n0)\n",
    "       plot_func_multiple_beta_doping(N,u[i],Mu,dtau,L,Pl_title_n2,Pl_x_lab,Pl_y_lab,Nden[i,:,:],M2_M2_conn_corr_n0[i,:,:],M2_M2_conn_corr_n1_std[i,:,:],Pl_name_conn_n0)\n",
    "       plot_func_multiple_beta_doping(N,u[i],Mu,dtau,L,Pl_title_n3,Pl_x_lab,Pl_y_lab,Nden[i,:,:],Nrm_M2_M2_conn_corr_n0[i,:,:],Nrm_M2_M2_conn_corr_n1_std[i,:,:],Pl_name_nrm_conn_n0)\n",
    "   \n",
    "       plot_func_multiple_beta_doping(N,u[i],Mu,dtau,L,Pl_title_n1,Pl_x_lab,Pl_y_lab,Nden[i,:,:],M2_M2_corr_n1[i,:,:],M2_M2_corr_n1_std[i,:,:],Pl_name_n1)\n",
    "       plot_func_multiple_beta_doping(N,u[i],Mu,dtau,L,Pl_title_n2,Pl_x_lab,Pl_y_lab,Nden[i,:,:],M2_M2_conn_corr_n1[i,:,:],M2_M2_conn_corr_n1_std[i,:,:],Pl_name_conn_n1)\n",
    "       plot_func_multiple_beta_doping(N,u[i],Mu,dtau,L,Pl_title_n3,Pl_x_lab,Pl_y_lab,Nden[i,:,:],Nrm_M2_M2_conn_corr_n1[i,:,:],Nrm_M2_M2_conn_corr_n1_std[i,:,:],Pl_name_nrm_conn_n1)\n",
    "       #plot_func_multiple_beta_doping(N,u[i],Mu,dtau,L,Pl_title_n1,Pl_x_lab,Pl_y_lab,Nden[i,:,:],Hl_db[i,:,:],Hl_db_std[i,:,:],Pl_name_hl_db)\n",
    "\n",
    "\n",
    "\n",
    "   for k in range(len(L)):\n",
    "       \n",
    "   #    Pl_name_n0 = \"%s/Moment_moment_correlation_onsite_normal_averaged_N_%s_dtau_%s_L_%s.png\"%(Graph_dir_U_comp,N,dtau,L[k])\n",
    "   #    Pl_name_conn_n0 = \"%s/Moment_moment_correlation_connected_onsite_normal_averaged_N_%s_dtau_%s_L_%s.png\"%(Graph_dir_U_comp,N,dtau,L[k])\n",
    "   #    Pl_name_nrm_conn_n0 = \"%s/Normalized_Moment_moment_correlation_connected_onsite_normal_averaged_N_%s_dtau_%s_L_%s.png\"%(Graph_dir_U_comp,N,dtau,L[k])\n",
    "\n",
    "   #    Pl_name_n1 = \"%s/Moment_moment_correlation_1st_nearest_neighbor_averaged_normal_averaged_N_%s_dtau_%s_L_%s.png\"%(Graph_dir_U_comp,N,dtau,L[k])\n",
    "   #    Pl_name_conn_n2 = \"%s/Moment_moment_correlation_connected_2nd_nearest_neighbor_averaged_normal_averaged_N_%s_dtau_%s_L_%s.png\"%(Graph_dir_U_comp,N,dtau,L[k])\n",
    "       \n",
    "       Pl_name_conn_n1 = \"%s/Moment_moment_correlation_connected_1st_nearest_neighbor_averaged_normal_averaged_N_%s_dtau_%s_L_%s.png\"%(Graph_dir_U_comp,N,dtau,L[k])\n",
    "   #    Pl_name_conn_nl = \"%s/Moment_moment_correlation_connected_non_local_normal_averaged_N_%s_dtau_%s_L_%s.png\"%(Graph_dir_U_comp,N,dtau,L[k])\n",
    "   #    Pl_name_nrm_conn_n1 = \"%s/Normalized_Moment_moment_correlation_connected_1st_nearest_neighbor_averaged_normal_averaged_N_%s_dtau_%s_L_%s.png\"%(Graph_dir_U_comp,N,dtau,L[k])\n",
    "       #Pl_name_conn_nl_vs_mu = \"%s/Moment_moment_correlation_connected_non_local_normal_averaged_N_%s_dtau_%s_L_%s.png\"%(Graph_dir,N,dtau,L[k])\n",
    "   #    Pl_name_conn_tot = \"%s/Total_Moment_moment_correlation_connected_normal_averaged_N_%s_dtau_%s_L_%s.png\"%(Graph_dir_U_comp,N,dtau,L[k])\n",
    "             \n",
    "   #    Pl_name_m2 = \"%s/Local_moment_normal_averaged_N_%s_dtau_%s_L_%s.png\"%(Graph_dir,N,dtau,L[k])\n",
    "   #    Pl_name_onsite_m2 = \"%s/Onsite_moment_normal_averaged_N_%s_dtau_%s_L_%s.png\"%(Graph_dir,N,dtau,L[k])\n",
    "   #    Pl_name_fluct = \"%s/Moment_fluctuations_N_%s_dtau_%s_L_%s.png\"%(Graph_dir,N,dtau,L[k])\n",
    "       \n",
    "   #    plot_func_multiple_U_doping(N,u,Mu,dtau,L[k],Pl_title_n1,Pl_x_lab,Pl_y_lab,Nden[:,:,k],M2_M2_corr_n0[:,:,k],M2_M2_corr_n1_std[:,:,k],Pl_name_n0)\n",
    "   #    plot_func_multiple_U_doping(N,u,Mu,dtau,L[k],Pl_title_n2,Pl_x_lab,Pl_y_lab,Nden[:,:,k],M2_M2_conn_corr_n0[:,:,k],M2_M2_conn_corr_n1_std[:,:,k],Pl_name_conn_n0)\n",
    "    #   plot_func_multiple_U_doping(N,u,Mu,dtau,L[k],Pl_title_n3,Pl_x_lab,Pl_y_lab,Nden[:,:,k],Nrm_M2_M2_conn_corr_n0[:,:,k],Nrm_M2_M2_conn_corr_n1_std[:,:,k],Pl_name_nrm_conn_n0)\n",
    "   \n",
    "   #    plot_func_multiple_U_doping(N,u,Mu,dtau,L[k],Pl_title_n1,Pl_x_lab,Pl_y_lab,Nden[:,:,k],M2_M2_corr_n1[:,:,k],M2_M2_corr_n1_std[:,:,k],Pl_name_n1)\n",
    "       plot_func_multiple_U_doping(N,u,Mu,dtau,L[k],Pl_title_n2,Pl_x_lab,Pl_y_lab,Nden[:,:,k],M2_M2_conn_corr_n1[:,:,k],M2_M2_conn_corr_n1_std[:,:,k],Pl_name_conn_n1)\n",
    "   #    plot_func_multiple_U_doping(N,u,Mu,dtau,L[k],Pl_title_n2,Pl_x_lab,Pl_y_lab,Nden[:,:,k],M2_M2_conn_corr_n2[:,:,k],M2_M2_conn_corr_n2_std[:,:,k],Pl_name_conn_n2)\n",
    "   #    plot_func_multiple_U_doping(N,u,Mu,dtau,L[k],Pl_title_n2,Pl_x_lab,Pl_y_lab,Nden[:,:,k],M2_M2_conn_corr_nl[:,:,k],M2_M2_conn_corr_nl_std[:,:,k],Pl_name_conn_nl)\n",
    "   #    plot_func_multiple_U_doping(N,u,Mu,dtau,L[k],Pl_title_n3,Pl_x_lab,Pl_y_lab,Nden[:,:,k],Nrm_M2_M2_conn_corr_n1[:,:,k],Nrm_M2_M2_conn_corr_n1_std[:,:,k],Pl_name_nrm_conn_n1)\n",
    "   #    plot_func_multiple_U_doping(N,u,Mu,dtau,L,Pl_title_n1,Pl_x_lab,Pl_y_lab,Nden[:,:,k],M2[:,:,k],M2_std[:,:,k],Pl_name_m2)\n",
    "   #    plot_func_multiple_U_doping(N,u,Mu,dtau,L[k],Pl_title_n2,Pl_x_lab,Pl_y_lab,Nden[:,:,k],M2_M2_conn_corr_tot[:,:,k],M2_M2_conn_corr_tot_std[:,:,k],Pl_name_conn_tot)\n",
    "   #    plot_func_multiple_U_doping(N,u,Mu,dtau,L[k],Pl_title_n2,Pl_x_lab,Pl_y_lab,Nden[:,:,k],Onsite_m2[:,:,k],Onsite_m2_std[:,:,k],Pl_name_onsite_m2)\n",
    "   #    plot_func_multiple_U_doping(N,u,Mu,dtau,L[k],Pl_title_n2,Pl_x_lab,Pl_y_lab,Nden[:,:,k],np.add(Onsite_m2[:,:,k],M2_M2_conn_corr_nl[:,:,k]),Onsite_m2_std[:,:,k],Pl_name_fluct)\n",
    "                      \n",
    "   #    plt.figure(figsize = (28,20))\n",
    "   #    plt.xticks(fontsize = 80)\n",
    "   #    plt.yticks(fontsize = 80)\n",
    "   #    for i in range(len(u)):\n",
    "   #        plt.errorbar(Mu_val[i,:,k],M2_M2_conn_corr_nl[i,:,k],yerr=M2_M2_conn_corr_nl_std[i,:,k],marker = \"o\",markersize = 20,label = \"U=%s\"%u[i])\n",
    "   #    plt.grid(True,which='both')\n",
    "   #    plt.legend(loc='best',fontsize = 50)\n",
    "   #    plt.savefig(\"%s/Non_local_moment_correlation_vs_mu_N_%s_dtau_%s_L_%s.png\"%(Graph_dir,N,dtau,L[k]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "661e1c90-7476-407e-898b-a89cdac44520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equal_time_moment_moment_correlation_function_doping_U_scaling(Text_dir_main_corr,Text_dir_main_eqm,Graph_dir,N,U,Mu,dtau,L):\n",
    "\n",
    "\n",
    "   Adj_list = adj_mat_calc(N)\n",
    "    \n",
    "   r_grid, r_rel_grid_size = r_point_upper_half_grid(N)\n",
    "   r_rel_x = r_grid[:,0]\n",
    "   r_rel_y = r_grid[:,1]\n",
    "\n",
    "   r_2 = np.add(np.power(r_rel_x,2),np.power(r_rel_y,2))\n",
    "   r_2_unq = np.sort(np.unique(r_2))\n",
    "\n",
    "   \n",
    "   M2_M2_conn_corr = np.zeros((len(Mu),len(U),len(r_2_unq)))\n",
    "   M2_M2_conn_corr_std = np.zeros((len(Mu),len(U),len(r_2_unq)))\n",
    "    \n",
    "   Nden = np.zeros((len(Mu),len(U)))\n",
    "   Nden_std = np.zeros((len(Mu),len(U)))\n",
    "\n",
    "\n",
    "\n",
    "   Mu_val = np.zeros(len(Mu))\n",
    "    \n",
    "   for j in range(len(Mu)):\n",
    "       Mu_val[j] = float(Mu[j])\n",
    "\n",
    "   Beta_val = np.zeros(len(L))\n",
    "   for k in range(len(L)):\n",
    "       Beta_val[k] = float(dtau)*float(L[k])\n",
    "\n",
    "   U_val = np.zeros(len(U))\n",
    "   for i in range(len(U)):\n",
    "       U_val[i] = float(U[i])\n",
    "    \n",
    "   for j in range(len(Mu)):\n",
    "       for k in range(len(U)):\n",
    "                       \n",
    "           Text_dir_eqm = \"%s/Text_files_N_%s_U_%s_dtau_%s/Mu_%s/dtau_%s_L_%s/Thermodynamic_measurements\"%(Text_dir_main_eqm,N,U[k],dtau,Mu[j],dtau,L)\n",
    "\n",
    "           filename_eqm_avg = '%s/Thermodynamic_measurements_normal_averaged_dictionary_N_%s_U_%s_mu_%s_dtau_%s_L_%s.pkl' %(Text_dir_eqm,N,U[k],Mu[j],dtau,L)\n",
    "           with open(filename_eqm_avg, 'rb') as infile:\n",
    "                sys_measure_avg = pickle.load(infile)\n",
    "\n",
    "           filename_eqm_std = '%s/Thermodynamic_measurements_normal_standard_deviation_dictionary_N_%s_U_%s_mu_%s_dtau_%s_L_%s.pkl' %(Text_dir_eqm,N,U[k],Mu[j],dtau,L)\n",
    "           with open(filename_eqm_std, 'rb') as infile:\n",
    "                sys_measure_std = pickle.load(infile)\n",
    "\n",
    "           Nden[j][k] = sys_measure_avg['Density averaged']\n",
    "           Nden_std[j][k] = sys_measure_std['Density standard deviation']\n",
    "           \n",
    "           Text_dir_m2_m2_conn_corr = '%s/Text_files_N_%s_U_%s_dtau_%s/Mu_%s/dtau_%s_L_%s/Moment_moment_connected_correlation_functions'%(Text_dir_main_corr,N,U[k],dtau,Mu[j],dtau,L)\n",
    "\n",
    "           filename_m2_m2_conn_corr = '%s/Equal_time_Moment_Moment_connected_correlation_real_space_neighbor_averaged_normal_avg_N_%s_U_%s_mu_%s_dtau_%s_L_%s.dat'%(Text_dir_m2_m2_conn_corr,N,U[k],Mu[j],dtau,L)\n",
    "           M2_M2_conn_corr[j,k,:],M2_M2_conn_corr_std[j,k,:] = np.loadtxt(filename_m2_m2_conn_corr,unpack = 'True', usecols = [1,2])\n",
    "    \n",
    " \n",
    "   M2_M2_conn_corr_n0 = np.zeros((len(Mu),len(U)))\n",
    "   M2_M2_conn_corr_n0_std = np.zeros((len(Mu),len(U)))\n",
    "\n",
    "   M2_M2_conn_corr_tot = np.zeros((len(Mu),len(U)))\n",
    "   M2_M2_conn_corr_n1 = np.zeros((len(Mu),len(U))) \n",
    "   M2_M2_conn_corr_tot_std = np.zeros((len(Mu),len(U)))\n",
    "   M2_M2_conn_corr_n1_std = np.zeros((len(Mu),len(U))) \n",
    "\n",
    "    \n",
    "   for j in range(len(Mu)):\n",
    "       for k in range(len(U)):\n",
    "\n",
    "           M2_M2_conn_corr_n0[j][k] = M2_M2_conn_corr[j][k][0]\n",
    "           M2_M2_conn_corr_n0_std[j][k] = M2_M2_conn_corr_std[j][k][0]\n",
    "\n",
    "           M2_M2_conn_corr_tot[j,k] = np.dot(M2_M2_conn_corr[j,k,:],Adj_list[:,1])\n",
    "           M2_M2_conn_corr_tot_std[j,k] = np.sqrt(np.dot(np.power(M2_M2_conn_corr_std[j,k,:],2),Adj_list[:,1])) \n",
    "           \n",
    "           M2_M2_conn_corr_n1[j,k] = M2_M2_conn_corr[j][k][1]\n",
    "           M2_M2_conn_corr_n1_std[j,k] = M2_M2_conn_corr_std[j][k][1] \n",
    "\n",
    "   #========================================Fitting data with cubic spline for temperature scaling=================\n",
    "\n",
    "   Graph_dir_data_fit = \"%s/Graph_spline_fit\"%Graph_dir \n",
    "   if not os.path.exists(Graph_dir_data_fit):\n",
    "       os.makedirs(Graph_dir_data_fit)\n",
    "       \n",
    "   nden_fit = np.asarray([1.0,1.05,1.07,1.10,1.15,1.20]) #,1.08,1.09,1.10])\n",
    "   nden_test = np.linspace(1.0,1.2,num=201)\n",
    "    \n",
    "   M2_corr_n0_fit = np.zeros((len(nden_fit),len(U)))    \n",
    "   M2_corr_tot_fit = np.zeros((len(nden_fit),len(U)))\n",
    "   M2_corr_n1_fit = np.zeros((len(nden_fit),len(U))) \n",
    "\n",
    "   #Comp_n0_fit = np.zeros((len(nden_fit),len(U)))    \n",
    "   #Comp_tot_fit = np.zeros((len(nden_fit),len(U)))\n",
    "   #Comp_nl_fit = np.zeros((len(nden_fit),len(U))) \n",
    "    \n",
    "   #Comp_derv_n0_fit = np.zeros((len(nden_fit),len(L)))    \n",
    "   #Comp_derv_tot_fit = np.zeros((len(nden_fit),len(L)))\n",
    "   #Comp_derv_nl_fit = np.zeros((len(nden_fit),len(L))) \n",
    "    \n",
    "   #T_val = np.zeros(len(L))\n",
    "    \n",
    "   for k in range(len(U)):\n",
    "       \n",
    "       #T_val[k] = 1/(float(dtau)*float(L[k]))\n",
    "       \n",
    "       x = Nden[:20,k]\n",
    "       y_n0 = M2_M2_conn_corr_n0[:20,k]\n",
    "       y_n1 = M2_M2_conn_corr_n1[:20,k]\n",
    "       y_tot = M2_M2_conn_corr_tot[:20,k]\n",
    "       \n",
    "       cs_n0 = CubicSpline(x,y_n0,bc_type='natural')\n",
    "       cs_n1 = CubicSpline(x,y_n1,bc_type='natural')\n",
    "       cs_tot = CubicSpline(x,y_tot,bc_type='natural')\n",
    "\n",
    "       plt.figure(figsize = (25,20))\n",
    "       plt.xticks(fontsize = 80)\n",
    "       plt.yticks(fontsize = 80)\n",
    "       plt.plot(x,y_n0,marker = \"o\",markersize = 25, label = \"n0\")\n",
    "       plt.plot(nden_test,cs_n0(nden_test),linewidth = 2)\n",
    "       plt.plot(x,y_n1,marker = \"+\",markersize = 25, label = \"nl\")\n",
    "       plt.plot(nden_test,cs_n1(nden_test),linewidth = 2)\n",
    "       plt.plot(x,y_tot,marker = \"^\", markersize = 25, label = \"tot\")\n",
    "       plt.plot(nden_test, cs_tot(nden_test),linewidth = 2)\n",
    "       plt.grid(True, which = 'both')\n",
    "       plt.legend(loc = 'best',fontsize= 40)\n",
    "       plt.savefig(\"%s/Spline_fit_N_%s_U_%s_dtau_%s_L_%s.png\"%(Graph_dir_data_fit,N,U[k],dtau,L))\n",
    "\n",
    "       M2_corr_n0_fit[:,k] = cs_n0(nden_fit)    \n",
    "       M2_corr_n1_fit[:,k] = cs_n1(nden_fit)\n",
    "       M2_corr_tot_fit[:,k] = cs_tot(nden_fit) \n",
    "\n",
    "       #Comp_n0_fit[:,k] = cs_n0(nden_fit)/T_val[k]  \n",
    "       #Comp_tot_fit[:,k] = cs_tot(nden_fit)/T_val[k]\n",
    "       #Comp_nl_fit[:,k] = cs_nl(nden_fit)/T_val[k]\n",
    "       \n",
    "   #Comp_derv_n0_fit = np.gradient(Comp_n0_fit,T_val,axis = 1)\n",
    "   #Comp_derv_tot_fit = np.gradient(Comp_tot_fit,T_val,axis = 1)\n",
    "   #Comp_derv_nl_fit = np.gradient(Comp_nl_fit,T_val,axis = 1) \n",
    "\n",
    "#=============================Density correlations=============================================================\n",
    "    \n",
    "   plt.figure(figsize = (25,20))\n",
    "   plt.xticks(fontsize = 80)\n",
    "   plt.yticks(fontsize = 80) \n",
    "   for i in range(len(nden_fit)):\n",
    "       Num = nden_fit[i]\n",
    "       plt.plot(U_val,M2_corr_n1_fit[i,:],marker = \"o\",markersize =20, label = \"n=%s\"%(str(round(Num,3))))\n",
    "   plt.grid(True, which = 'both')\n",
    "   plt.legend(loc = 'best',ncol =2,fontsize = 60)\n",
    "   plt.tight_layout() \n",
    "   plt.savefig(\"%s/Temperature_scaling_nearest_moment_correlation_N_%s_dtau_%s_L_%s.png\"%(Graph_dir_data_fit,N,dtau,L))\n",
    "\n",
    "   plt.figure(figsize = (25,20))\n",
    "   plt.xticks(fontsize = 80)\n",
    "   plt.yticks(fontsize = 80) \n",
    "   for i in range(len(nden_fit)):\n",
    "       Num = nden_fit[i]\n",
    "       plt.plot(U_val,M2_corr_tot_fit[i,:],marker = \"o\",markersize =20, label = \"n=%s\"%(str(round(Num,3))))\n",
    "   plt.grid(True, which = 'both')\n",
    "   plt.legend(loc = 'best',ncol=2,fontsize = 60)\n",
    "   plt.tight_layout() \n",
    "   plt.savefig(\"%s/Temperature_scaling_total_moment_correlation_N_%s_U_%s_dtau_%s.png\"%(Graph_dir_data_fit,N,dtau,L))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5168a8a-034a-4de4-8f0e-41dcb14e1580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    N = \"10\"\n",
    "    Dtau = \"0.05\"\n",
    "\n",
    "    U=[\"1.0\",\"4.00\",\"5.0\",\"6.00\",\"8.0\",\"10.00\"] #,\"10.00\"] #,\"6.00\",\"6.50\",\"7.0\",\"8.0\",\"9.0\"] #,\"6.00\",\"6.50\",\"8.00\"] #.0\",\"2.0\",\"3.0\",\"5.0\",\"7.0\",\"9.0\"] #,\"11.00\",\"12.00\"]\n",
    "    #Mu =\"0.00\"\n",
    "    Trot = [\"30\"] #,\"30\",\"40\",\"50\",\"60\"] #\"22\",\"24\",\"26\",\"28\",\"30\",\"32\",\"34\",\"36\",\"38\",\"40\",\"42\",\"44\",\"46\",\"48\",\"50\",\"54\",\"56\",\"60\"]\n",
    "    U_hf=[\"1.00\",\"1.50\",\"2.00\",\"2.50\",\"3.00\",\"3.50\",\"4.00\",\"4.50\",\"5.00\",\"5.50\",\"6.00\",\"6.50\",\"7.00\",\"7.50\",\"8.00\",\"8.50\",\"9.00\",\"9.50\",\"10.00\",\"10.50\",\"11.00\",\"11.50\",\"12.00\",\"12.50\"]\n",
    "    #U = [\"1.0\",\"4.0\",\"5.0\",\"6.0\",\"8.0\",\"10.0\"] #[\"3.30\",\"3.40\",\"3.50\",\"3.60\",\"3.70\",\"3.80\",\"3.90\",\"4.00\",\"4.10\",\"4.20\",\"4.30\",\"4.40\"]\n",
    "    U_hf=[\"1.00\",\"1.50\",\"2.00\",\"2.50\",\"3.00\",\"3.50\",\"4.00\",\"4.50\",\"5.00\",\"5.50\",\"6.00\",\"6.50\",\"7.00\",\"7.50\",\"8.00\",\"8.50\",\"9.00\",\"9.50\",\"10.00\"]#,\"10.50\",\"11.00\",\"11.50\",\"12.00\",\"12.50\"]\n",
    "   \n",
    "    Mu = [\"0.00\",\"0.20\",\"0.40\",\"0.60\",\"0.80\",\"1.00\",\"1.20\",\"1.40\",\"1.60\",\"1.80\",\"2.00\",\"2.50\",\"3.00\",\"3.50\",\"4.00\",\"4.50\",\"5.00\",\"5.50\",\"6.00\",\"6.50\",\"7.00\",\n",
    "          \"7.50\",\"8.00\",\"8.50\",\"9.00\",\"9.50\",\"10.00\"]\n",
    "    #Mu_hf =\"0.00\"\n",
    "    #Mu = [\"-10.00\",\"-9.50\",\"-9.00\",\"-8.50\",\"-8.00\",\"-7.50\",\"-7.00\",\"-6.50\",\"-6.00\",\"-5.50\",\"-5.00\",\"-4.50\",\"-4.00\",\"-3.50\",\"-3.00\",\"-2.50\",\n",
    "    #      \"-2.00\",\"-1.80\",\"-1.60\",\"-1.40\",\"-1.20\",\"-1.00\",\"-0.80\",\"-0.60\",\"-0.40\",\"-0.20\",\"0.00\",\"0.20\",\"0.40\",\"0.60\",\"0.80\",\"1.00\",\"1.20\",\n",
    "    #      \"1.40\",\"1.60\",\"1.80\",\"2.00\",\"2.50\",\"3.00\",\"3.50\",\"4.00\",\"4.50\",\"5.00\",\"5.50\",\"6.00\",\"6.50\",\"7.00\",\n",
    "    #      \"7.50\",\"8.00\",\"8.50\",\"9.00\",\"9.50\",\"10.00\"]\n",
    "    #Trot = [\"20\",\"30\"] #,\"40\",\"50\"] #,\"50\",\"60\"]\n",
    "    Trot_hf = [\"20\",\"22\",\"24\",\"26\",\"28\",\"30\",\"32\",\"34\",\"36\",\"38\",\"40\",\"42\",\"44\",\"46\",\"48\",\"54\",\"56\",\"60\"]\n",
    "    \n",
    "    Text_dir_main_corr = '/Users/roy.369/Documents/Cold_atom_correlators/FHM_Legacy_data/FHM_Roy_data/Text_files/Text_files_N_%s_real_space_correlations'%N\n",
    "    Text_dir_main_eqm = '/Users/roy.369/Documents/Cold_atom_correlators/FHM_Legacy_data/FHM_Roy_data/Text_files/Text_files_N_%s'%N\n",
    "    \n",
    "    Text_dir_main_corr_hf = '/Users/roy.369/Documents/Cold_atom_correlators/FHM_Legacy_data/FHM_Roy_data/Text_files/Text_files_N_%s_real_space_correlations_half_filling'%N\n",
    "    Text_dir_main_eqm_hf = '/Users/roy.369/Documents/Cold_atom_correlators/FHM_Legacy_data/FHM_Roy_data/Text_files/Text_files_N_%s_half_filling'%N\n",
    "\n",
    "    \n",
    "    Graph_dir_hf = '/Users/roy.369/Documents/Cold_atom_correlators/FHM_Legacy_data/FHM_Roy_data/Graphs/Graphs_N_%s/Graphs_N_%s_dtau_%s_half_filling_real_space_correlations_normal_averaged/Moment_moment_correlations'%(N,N,Dtau)\n",
    "    if not os.path.exists(Graph_dir_hf):\n",
    "        os.makedirs(Graph_dir_hf)\n",
    "\n",
    "    Graph_dir = '/Users/roy.369/Documents/Cold_atom_correlators/FHM_Legacy_data/FHM_Roy_data/Graphs/Graphs_N_%s/Graphs_N_%s_dtau_%s_real_space_correlations_normal_averaged/Moment_moment_correlations'%(N,N,Dtau)\n",
    "    if not os.path.exists(Graph_dir):\n",
    "        os.makedirs(Graph_dir)\n",
    "\n",
    "    #equal_time_moment_moment_correlation_function_half_filling(Text_dir_main_corr_hf,Text_dir_main_eqm_hf,Graph_dir_hf,N,U_hf,\"0.00\",Dtau,Trot_hf)\n",
    "    equal_time_moment_moment_correlation_function_doping(Text_dir_main_corr,Text_dir_main_eqm,Graph_dir,N,U,Mu,Dtau,Trot)\n",
    "    #equal_time_moment_moment_correlation_function_doping_U_scaling(Text_dir_main_corr,Text_dir_main_eqm,Graph_dir,N,U,Mu,Dtau,Trot[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d8b921a-f9e5-4214-bbce-49bf787203bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "/Users/roy.369/Documents/Cold_atom_correlators/FHM_Legacy_data/FHM_Roy_data/Text_files/Text_files_N_10_real_space_correlations/Text_files_N_10_U_4.00_dtau_0.05/Mu_0.50/dtau_0.05_L_30/Moment_moment_connected_correlation_functions/Equal_time_Moment_Moment_connected_correlation_real_space_neighbor_averaged_normal_avg_N_10_U_4.00_mu_0.50_dtau_0.05_L_30.dat not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m main()\n",
      "Cell \u001b[0;32mIn[31], line 39\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(Graph_dir)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m#equal_time_moment_moment_correlation_function_half_filling(Text_dir_main_corr_hf,Text_dir_main_eqm_hf,Graph_dir_hf,N,U_hf,\"0.00\",Dtau,Trot_hf)\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m equal_time_moment_moment_correlation_function_doping(Text_dir_main_corr,Text_dir_main_eqm,Graph_dir,N,U,Mu,Dtau,Trot)\n",
      "Cell \u001b[0;32mIn[27], line 77\u001b[0m, in \u001b[0;36mequal_time_moment_moment_correlation_function_doping\u001b[0;34m(Text_dir_main_corr, Text_dir_main_eqm, Graph_dir, N, u, Mu, dtau, L)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m#Text_dir_den_dbn_conn_corr = '%s/Text_files_N_%s_U_%s_dtau_%s/Mu_%s/dtau_%s_L_%s/Density_doublon_connected_correlation_functions'%(Text_dir_main_corr,N,u[i],dtau,Mu[j],dtau,L[k])\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m#filename_den_dbn_conn_corr = '%s/Equal_time_Density_Doublon_connected_correlation_real_space_neighbor_averaged_normal_avg_N_%s_U_%s_mu_%s_dtau_%s_L_%s.dat'%(Text_dir_den_dbn_conn_corr,N,u[i],Mu[j],dtau,L[k])\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m#filename_m2_m2_corr = '%s/Equal_time_Moment_Moment_correlation_real_space_neighbor_averaged_normal_avg_N_%s_U_%s_mu_%s_dtau_%s_L_%s.dat'%(Text_dir_m2_m2_corr,N,u[i],Mu[j],dtau,L[k])\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m#M2_M2_corr[i,j,k,:],M2_M2_corr_std[i,j,k,:] = np.loadtxt(filename_m2_m2_corr,unpack = 'True', usecols = [1,2])\u001b[39;00m\n\u001b[1;32m     76\u001b[0m filename_m2_m2_conn_corr \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m/Equal_time_Moment_Moment_connected_correlation_real_space_neighbor_averaged_normal_avg_N_\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_U_\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_mu_\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_dtau_\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_L_\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.dat\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m%\u001b[39m(Text_dir_m2_m2_conn_corr,N,u[i],Mu[j],dtau,L[k])\n\u001b[0;32m---> 77\u001b[0m M2_M2_conn_corr[i,j,k,:],M2_M2_conn_corr_std[i,j,k,:] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mloadtxt(filename_m2_m2_conn_corr,unpack \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrue\u001b[39m\u001b[38;5;124m'\u001b[39m, usecols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(r_2_unq)):\n\u001b[1;32m     82\u001b[0m     Nrm_M2_M2_conn_corr[i,j,k,r] \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m(M2[i][j][k]\u001b[38;5;241m*\u001b[39mM2[i][j][k]))\u001b[38;5;241m*\u001b[39m(M2_M2_conn_corr[i,j,k,r])\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/numpy/lib/npyio.py:1373\u001b[0m, in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(delimiter, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m   1371\u001b[0m     delimiter \u001b[38;5;241m=\u001b[39m delimiter\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1373\u001b[0m arr \u001b[38;5;241m=\u001b[39m _read(fname, dtype\u001b[38;5;241m=\u001b[39mdtype, comment\u001b[38;5;241m=\u001b[39mcomment, delimiter\u001b[38;5;241m=\u001b[39mdelimiter,\n\u001b[1;32m   1374\u001b[0m             converters\u001b[38;5;241m=\u001b[39mconverters, skiplines\u001b[38;5;241m=\u001b[39mskiprows, usecols\u001b[38;5;241m=\u001b[39musecols,\n\u001b[1;32m   1375\u001b[0m             unpack\u001b[38;5;241m=\u001b[39munpack, ndmin\u001b[38;5;241m=\u001b[39mndmin, encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m   1376\u001b[0m             max_rows\u001b[38;5;241m=\u001b[39mmax_rows, quote\u001b[38;5;241m=\u001b[39mquotechar)\n\u001b[1;32m   1378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/numpy/lib/npyio.py:992\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[1;32m    990\u001b[0m     fname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(fname)\n\u001b[1;32m    991\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fname, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 992\u001b[0m     fh \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlib\u001b[38;5;241m.\u001b[39m_datasource\u001b[38;5;241m.\u001b[39mopen(fname, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrt\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39mencoding)\n\u001b[1;32m    993\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m encoding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    994\u001b[0m         encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fh, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/numpy/lib/_datasource.py:193\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03mOpen `path` with `mode` and return the file object.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    189\u001b[0m \n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m ds \u001b[38;5;241m=\u001b[39m DataSource(destpath)\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ds\u001b[38;5;241m.\u001b[39mopen(path, mode, encoding\u001b[38;5;241m=\u001b[39mencoding, newline\u001b[38;5;241m=\u001b[39mnewline)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/numpy/lib/_datasource.py:533\u001b[0m, in \u001b[0;36mDataSource.open\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _file_openers[ext](found, mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m    531\u001b[0m                               encoding\u001b[38;5;241m=\u001b[39mencoding, newline\u001b[38;5;241m=\u001b[39mnewline)\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 533\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: /Users/roy.369/Documents/Cold_atom_correlators/FHM_Legacy_data/FHM_Roy_data/Text_files/Text_files_N_10_real_space_correlations/Text_files_N_10_U_4.00_dtau_0.05/Mu_0.50/dtau_0.05_L_30/Moment_moment_connected_correlation_functions/Equal_time_Moment_Moment_connected_correlation_real_space_neighbor_averaged_normal_avg_N_10_U_4.00_mu_0.50_dtau_0.05_L_30.dat not found."
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af7fe14-a038-4ec2-959e-91a4044910d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc100ce-2be9-4311-a300-b07a1b50affd",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_1 = np.asarray([1.2208436724565757, 1.2109181141439205, 1.1910669975186106])\n",
    "N_2 = np.asarray([1.211864406779661,1.2070217917675543, 1.194915254237288])\n",
    "N_3 = np.asarray([1.208816338157447,1.2063950498104907,1.2003418289430996])\n",
    "N_4 = np.asarray([1.197768125317684,1.197768125317684,1.197768125317684])\n",
    "N_4p5 = np.asarray([1.1973365617433411,1.1973365617433411,1.1973365617433411])\n",
    "N_5 = np.asarray([1.191283292978208,1.191283292978208,1.1949152542372878])\n",
    "N_5p5 = np.asarray([\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6f72cf-cd22-4bd4-85dd-7df67c994016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7220704f-5e39-49d0-91d8-996174862b72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47652fc6-1174-4535-ba16-b50d3e018828",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73e044b-04a0-414e-a31d-c60bfa5cb39a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
